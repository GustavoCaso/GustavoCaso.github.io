[{"content":"","date":"19 September 2020","permalink":"/tags/concurrency/","section":"Tags","summary":"","title":" concurrency"},{"content":"","date":"19 September 2020","permalink":"/","section":"Gustavo Caso","summary":"","title":"Gustavo Caso"},{"content":"","date":"19 September 2020","permalink":"/posts/","section":"Posts","summary":"","title":"Posts"},{"content":"","date":"19 September 2020","permalink":"/tags/ruby/","section":"Tags","summary":"","title":"ruby"},{"content":"","date":"19 September 2020","permalink":"/tags/","section":"Tags","summary":"","title":"Tags"},{"content":"I was reading a fantastic article from my colleague Kir, and I could help myself to feel nerd snipped by:\nFor those curious to try Ractor, I\u0026rsquo;d suggest to try implementing other things that benefit from parallel execution, for instance a background job processor.\nWhat is a background job processor? # A background job processor allows you to offload heavy computational tasks from the main process to other processes.\nImagine a typical request/response inside a Rails app, you would like to provide your users with the fastest response, but some requests have operations associated with it that could derail the response. A good example could be sending emails.\nIs very common in the Rails community to offload those task into a background job processor.\nThe most common libraries used for that are: sidekiq, resque, and sucker_punch\nLet\u0026rsquo;s build a background job processor using Ractor # Before continuing reading, I recommend having a look at Ractor documentation.\nHere is a simple diagram of our background job processor.\n+ +----+ | Separate Process | | | | W | +----------------+ | +--------------------+ +----+ | | | | | +----+ | Main Process | | | | | | | (Rails app) | | | Job Processor | | W | | | | | | +----+ +-------+--------+ | | Takes work from | +----+ | | | the queue and | | | | +---------+ | | send it to the | | W | | Push | | | | workers | +----+ +------------\u0026gt; | Queue +------\u0026gt;+ | +----+ +---------+ | | | | | | | | | W | | | | +----+ | | | +----+ | +--------------------+ | | | | W | | W = Worker +----+ | | + For the Queue part, we are going to use redis.\nOur main process:\nQUEUE_NAME = \u0026#34;jobs:queue:low\u0026#34; redis = Redis.new redis.rpush(QUEUE_NAME, new_job) The main process will write work into the queue, and our background job processor will dequeue that work and execute it.\nLet\u0026rsquo;s start building our job processor.\nredis = Redis.new loop do puts \u0026#34;Waiting on work\u0026#34; queue, job = redis.brpop(QUEUE_NAME) puts \u0026#34;Pushing work from #{queue} to available workers\u0026#34; pipe.send(job, move: true) end You can see here that we have an endless loop. The idea of the job processor is to check for work in the queue (QUEUE_NAME)\nThe command BRPOP blocks until there is data in the queue. Once it finds something in the queue, it passes to the pipe.\nWhat is a pipe? # pipe = Ractor.new do loop do Ractor.yield(Ractor.recv, move: true) end end I like to think of it as IPC (Inter-process communication) but with Ractors.\nOne Ractor push something, and another Ractor takes it.\n+----------------+ +-----------------+ | | +--------------+ | | | | push | | take | | | Ractor 1 +--------\u0026gt;+ Pipe +-------\u0026gt;+ Ractor 2 | | | | | | | | | +--------------+ | | +----------------+ +-----------------+ The pipe is going to allows us to communicate between the job processor and the workers.\nLastly, we have our set of workers that are going to be waiting for the job processor to signal when them when there is work to do.\nNUMBER_OF_WORKERS = 10 workers = NUMBER_OF_WORKERS.times.map do |index| worker = Worker.new(index) Ractor.new(pipe, worker) do |pipe, worker| loop do # this is a blocking operation # This Ractor will wait until there is a something to take from the pipe job = pipe.take puts \u0026#34;taken job from pipe by #{Ractor.current} and work it by worker #{worker.id}\u0026#34; worker.work(job) end end end I omitted the code for the Worker class but will include everything at the end of the article.\nHere is the complete job scheduler code:\npipe = Ractor.new do loop do Ractor.yield(Ractor.recv, move: true) end end workers = 4.times.map do |index| worker = Worker.new(index) Ractor.new(pipe, worker) do |pipe, worker| loop do job = pipe.take puts \u0026#34;taken job from pipe by #{Ractor.current} and work it by worker #{worker.id}\u0026#34; worker.work(job) end end end redis = Redis.new loop do puts \u0026#34;Waiting on work\u0026#34; queue, job = redis.brpop(QUEUE_NAME) puts \u0026#34;Pushing work from #{queue} to available workers\u0026#34; pipe.send(job, move: true) end It couldn\u0026rsquo;t get more straightforward than that.\nLimitations with Ractor: # I tried to encapsulate the main loop inside a Ractor, but due to the sharing limitations of Ractor, I wasn\u0026rsquo;t able.\njob_server = Ractor.new(pipe, QUEUE_NAME) do |pipe, queue_name| redis = Redis.new loop do puts \u0026#34;Waiting on work\u0026#34; queue, job = redis.brpop(queue_name) puts \u0026#34;Pushing work from #{queue} to available workers\u0026#34; pipe.send(job, move: true) end end loop do Ractor.listen(job_server, *workers) end I got the error:\nthrown by remote Ractor. (Ractor::RemoteError) from /Users/gustavocaso/Desktop/ractor.rbüíØin `block in \u0026lt;main\u0026gt;\u0026#39; from /Users/gustavocaso/Desktop/ractor.rb:99:in `loop\u0026#39; from /Users/gustavocaso/Desktop/ractor.rb:99:in `\u0026lt;main\u0026gt;\u0026#39; /usr/local/lib/ruby/gems/3.0.0/gems/redis-4.2.2/lib/redis/client.rb:406:in `_parse_options\u0026#39;: can not access non-sharable objects in constant Redis::Client::DEFAULTS by non-main ractor. (NameError) The Redis::Client::DEFAULTS constant is not sharable inside Ractors code\nI had a similar issue when trying to use the ruby JSON library. I had to use oj to parse the job after dequeuing from Redis.\nConclusions # Even with the sharing limitations of Ractor, I\u0026rsquo;m very excited about the new possibilities that it will enable to ruby developers.\nAs Kir\u0026rsquo;s said in his article, I would encourage anyone to experiment with it.\nHere is the complete gist of the code so you can experiment with it.\n","date":"19 September 2020","permalink":"/posts/writing-a-ractor-base-job-scheduler/","section":"Posts","summary":"I was reading a fantastic article from my colleague Kir, and I could help myself to feel nerd snipped by:\nFor those curious to try Ractor, I\u0026rsquo;d suggest to try implementing other things that benefit from parallel execution, for instance a background job processor.","title":"Writing a Ractor Base Job Scheduler"},{"content":"","date":"14 March 2020","permalink":"/tags/websockets/","section":"Tags","summary":"","title":" WebSockets"},{"content":"With the current global situation and the need to stay home, I decided to finish writing this post that I started during the last Christmas holidays.\nDuring Christmas, I wanted to learn more about the WebSockets protocol.\nFor that, I thought a simple chat app would be a good exercise.\nI went on the internet and searched for tutorials on how to build a chat app using WebSockets and Go, but I could not find any tutorial that showed a more realistic example. The majority of the samples were echo servers.\nI wanted some examples that involved some user interaction.\nI wanted to build something that resembles more a real chat like Slack, WhatsApp, Telegram, etc.. There are many examples out there.\nFull disclosure I\u0026rsquo;m not a professional Go developer, but I\u0026rsquo;m slowly learning for personal projects, and work.\nOk, let\u0026rsquo;s start!!\nFirst, we need to decide which WebSocket library to use, Go provides a WebSocket library, but the Go team advises to use other solutions built by the community. You can even see a message when you want to read the doc for the library in GoDoc.\nI decided to use websocket because it was the most recent of all and had support for context and rate-limiting.\nOnce we move away from deciding on the WebSocket library, we need a way to route request to our server, Go provides a fantastic http package for doing that. Still, often I find myself reaching for another solution from the community to build the routes. Not for any technical reason, but it was the first library I used to create a web app some time ago, and I\u0026rsquo;m sticking with what I know and have worked for me.\nBefore we continue, I want to make clear that this post is not going to discuss goroutines synchronization, there is fantastic documentation on the sync package and tones of resources out there. So far, simplicity, I\u0026rsquo;m going to remove those bits from the code examples.\nFantastic, we are ready to start building the CLI chat app.\nSo I want to divide the code between server and client.\nThe server handles new WebSocket connections, listen to messages on those socket connections and broadcast messages to the right users. Also, it takes care of adding and removing users to different chat rooms.\nThe client connects to the server, listens to messages that are sent to it and print them. It also allows the users to submit new messages to the server.\nThose are going to be our two Go packages.\nLet\u0026rsquo;s start with the server: # The server must provide an endpoint that clients can connect using the WebSocket protocol, for that we are going to use the Http.Server abstraction that the Http package provides.\nThe handler is going to have a single route /chat/:chat_room/:user_name.\nWe have four abstractions: Hub, Chat, Message and User.\nThe Hub will hold a list of chats. You can think of the hub as a workspace in Slack; each workspace has different chat rooms.\nWhen a user opens a WebSocket connection to /chat/general/gustavo, we are going to check if the chat general exists. If not, we will create it, store in the Hub and add gustavo to the list of users of that chat. If the chat room exists, we will check if the user already is there and if not create a new user or return an error message if the user already exists.\nfunc (h *hub) chatRoom(w http.ResponseWriter, r *http.Request, ps httprouter.Params) { chatRoom := ps.ByName(\u0026#34;chat_room\u0026#34;) userName := ps.ByName(\u0026#34;user_name\u0026#34;) c, ok := h.rooms[chatRoom] if !ok { c := h.addChat(chatRoom) user, err := newUser(userName, w, r) if err != nil { log.WithError(err).Fatal(\u0026#34;Error creating user to new chat\u0026#34;) } c.addUser(user) c.run() } else { if c.hasUser(userName) { log.WithFields(log.Fields{ \u0026#34;chat\u0026#34;: chatRoom, \u0026#34;username\u0026#34;: userName, }).Info(\u0026#34;User already exists in chat room\u0026#34;) } else { user, err := newUser(userName, w, r) if err != nil { log.WithError(err).Fatal(\u0026#34;Error creating user for chat\u0026#34;) } else { c.addUser(user) } } } } The chat holds a list of users connected to that chat. The most important thing that the chat does is acting as a coordinator between the multiple goroutines that will work to make listening, broadcasting and managing users possible.\nBefore we continue, we need to know what a user is. The user holds the name and the WebSocket connection for that particular user.\ntype user struct { name string conn *websocket.Conn listening bool } The user connection is an important detail because the chat uses those connections both for listening to messages and broadcasting messages to the right client.\nNow that we know how the user and chat works let\u0026rsquo;s dive into how we can listen, broadcast and keep the users updated for each chat.\nOnce we create a chat room, we are going to call the run function, which will start three different goroutines.\nfunc (c *chat) run() { go c.listen() go c.broadcast() go c.keepUserListUpdated() } The listen goroutine, loops over all the users on the chat and creates another goroutine to listen to incoming messages. After receiving the message, we send it to the internal messages channel.\nfunc (c *chat) listen() { for { if len(c.users) \u0026gt; 0 { for _, user := range c.users { if !user.listening { user.listening = true go c.listenToUser(user) } } } } } func (c *chat) listenToUser(user *user) { for { _, msg, err := user.conn.Read(c.ctx) if err == nil { c.messages \u0026lt;- message{ bytes: msg, author: user, } } else { c.dropUsers \u0026lt;- user break } } } It is essential to mention that if we get an error while listening to a message from a user, we are going to send a message to the dropUsers channel. We are going to use this channel on the keepUserListUpdated function.\nWhy do we need a separate goroutine per user? Great question. The act of listening for a message in the WebSocket connection is a blocking action. So when iterating over the users, it will stop and wait for the first user to send a message, once the user has sent a message it will iterate to the next user and repeat the process.\nIf we do not create a different goroutine, we will listen to the messages in the order the users have connected to the chat. But we want to have a real-time experience when sending and receiving messages on our CLI chat app.\nThe broadcast goroutine listens on the messages channel, and every time we get a new message, we are going to send it to all the users except to the author of the message.\nfunc (c *chat) broadcast() { loop: for { select { case message := \u0026lt;-c.messages: usersToSend := c.userToSend(message.author) bytes, err := message.print() if err == nil { for _, user := range usersToSend { user.conn.Write(c.ctx, websocket.MessageText, bytes) } c.messagesRead = append(c.messagesRead, message) } else { log.WithError(err).Warn(\u0026#34;Error building the message\u0026#34;) } case \u0026lt;-c.ctx.Done(): break loop } } } Finally, our last goroutine is the keepUserListUpdated, which takes care of adding and removing users on each chat. We remove users from the chat every time there is an error reading from the WebSocket connection. You can check listenToUser above to see the logic that handles those cases.\nRemember that previously we mentioned that when there is an error listening to users, we send a message to the dropUsers channel?\nThe keepUserListUpdated function listens to that channel, and every time a new message comes, it deletes the user from the list of active users in the chat.\nfunc (c *chat) keepUserListUpdated() { loop: for { select { case user := \u0026lt;-c.addedUsers: users := c.users users = append(users, user) c.users = users c.broadcastMessage([]byte(fmt.Sprintf(\u0026#34;%s joined %s\\n\u0026#34;, user.name, c.name))) case user := \u0026lt;-c.dropUsers: users := c.deleteUser(user) c.users = users case \u0026lt;-c.ctx.Done(): break loop } } } This function also takes care of adding users to the chat in a similar way, with the addition of broadcasting to all users that a new user joined the chat.\nAnd that is all there is to the server package.\nLet\u0026rsquo;s dive into the client-side of the CLI app. # The client functionality is to connect to the server, listen for new messages, print them and allow the users to send new messages to the server.\nIn our example, the client store the name of the user, a WebSocket connection to the server and a channel which we will use to send messages.\ntype client struct { userName string conn *websocket.Conn ctx context.Context message chan string } When using the CLI as a client, we need to pass the chat room and the user who is connecting to it.\ngo run client/main.go --user_name=gustavo --chat_room=general\nExecuting that line will open a new connection to the server using the WebSocket protocol. ws://localhost:8080/chat/general/gustavo, notice that we haven\u0026rsquo;t used http or http on the URL but rather ws.\nAll this logic is taking care of by the WebSocket library we are using.\nOnce the client has initialized, we are going to call the run method, which will start two new goroutines: listen and getInput.\nThe listen goroutine is very similar to the one on the server, but we do not have to loop over the different users since here we only have one user listening for messages.\nfunc (c *client) listen() { for { _, reader, err := c.conn.Reader(c.ctx) if err != nil { log.WithError(err).Warn(\u0026#34;Error receiving message\u0026#34;) break } else { io.Copy(os.Stdout, reader) } } } What is that io.Copy(os.Stdout, reader) doing? It gets the message from the WebSocket and copies to the terminal stdout. Go provides the Reader and Writer abstractions that help us manipulate data between entities that implement the reader and writer interface.\nThe getInput function is a simple for loop that will listen for the user input coming from the terminal stdin. Once we have a message from the user, we are going to send that message to the message channel of the client.\nfunc (c *client) getInput() { for { in := bufio.NewReader(os.Stdin) result, err := in.ReadString(\u0026#39;\\n\u0026#39;) if err != nil { log.WithError(err).Fatal(err) } if result != \u0026#34;\u0026#34; { c.message \u0026lt;- result } } } It makes sure that it is not empty since the user could use the return key, but haven\u0026rsquo;t type anything, and we do not want to send blank messages to the server, that will get broadcast to all the users of the chat.\nFinally, we have another for loop and select listening for messages on the message channel and every time we get a new message, we are going to write to the server.\nfunc (c *client) run() { go c.listen() go c.getInput() loop: for { select { case text := \u0026lt;-c.message: err := c.conn.Write(c.ctx, websocket.MessageText, []byte(text)) if err != nil { break loop } case \u0026lt;-c.ctx.Done(): break loop } } c.close() } And this is all that you need to create a CLI chat app with go and WebSockets. I hope you enjoyed reading as much as I enjoyed writing the app and the article. If you have any questions, please use the comments below, and I will answer them.\nYou can find all the code here\nOne last thing, I know the functionality is far from complete, but I haven\u0026rsquo;t got the time to work more on it if you are curious and want to improve the app here a list of things you could work on:\nBroadcast all previous messages, when a new user connects to the chat. Handle connection retry both on the server and the client. ","date":"14 March 2020","permalink":"/posts/building-a-cli-chat-app-with-go-and-websockets/","section":"Posts","summary":"With the current global situation and the need to stay home, I decided to finish writing this post that I started during the last Christmas holidays.\nDuring Christmas, I wanted to learn more about the WebSockets protocol.","title":"Building a CLI chat app with go and WebSockets"},{"content":"","date":"14 March 2020","permalink":"/tags/go/","section":"Tags","summary":"","title":"go"},{"content":"Here at Shopify, I work as a Production Engineer on the Jobs team. Our mission is to maintain and improve the background job infrastructure for Shopify Core, which happens to be one of the largest Ruby on Rails applications in the World.\nLet\u0026rsquo;s start with some context about Background Jobs, especially in the context of ruby applications. When talking about jobs, we refer to those units of work that are important for the application to function but would take too long to be processed within the lifetime of a web request. The usual way of dealing with those units is to offload them to the background, aka \u0026ldquo;background jobs\u0026rdquo;, and for a different process to pick those jobs and execute them.\nIn Ruby land, there are many popular options for dealing with jobs. The most commonly used one is Sidekiq and we have others like Resque, Delayed job, Sucker punch\u0026hellip;\nThis post is not going to focus on how those libraries work or what are their differences, but rather why at Shopify, we decided to build our internal library for dealing with jobs.\nTo provide a little more context, at Shopify, in the beginning, we were using Delayed job, which was created by Tobias L√ºtke, current CEO of Shopify. The backend used to store jobs was MySQL, and at some point, MySQL wasn\u0026rsquo;t able to keep with the amount of writes jobs were creating. Later Github released Resque in November of 2009, which uses Redis as the backend to store jobs. At that time, it was the only option that could support the requirements of Shopify. Since then, we have added functionality on top of Resque with external gems like resque-scheduler or resque-pool.\nOf course, the requirements of the application always change, and the library that you are using might not evolve the way that would satisfy your new needs.\nThroughout the years of Shopify, the complexity of our monolith kept increasing as our needs kept evolving. As a result, we introduced sharding and new sophisticated job primitives. For many years, resque and the other gems helped to solve these problems, but those libraries could no longer provide all the functionality that Shopify needed. We had to regularly hack or patch the library so we could keep providing the functionality that was required.\nYou can imagine that for the maintainers of this system, this was not ideal. We were working with at least three resque-* gems and dozens of custom modules that provided extra functionality. This situation was the cause of frustration, production errors, and a complex enough system that it was difficult to grasp in one\u0026rsquo;s head. Most critically, adding new features was laborious and error-prone.\nAt the beginning of this year, my team decided that we were going to aggregate all resque code and all the custom functionality that we have built over the years and place everything under one library.\nAfter four months of work, we are currently running all jobs from the monolith with our library, and we have ported all previous patches into our library at the time this post is published.\nThis decision has allowed the team to work on major refactors to the internals of the job infrastructure and adapt to new requirements that appeared throughout the year.\nThanks to that decision, adding those new features was smooth, and the team confidence on the code base has increased substantially, more importantly, we are in a much better place to keep improving the job infrastructure.\nHere at Shopify, we value open-source projects, and we contribute to them as much as we can. But even though that is the mentality at Shopify, there are occasions were owning all of the code has more benefits in the long term.\nThe conclusion that I wanted to leave here is that if you or your team find yourselves often working around library functionality, finding hacky ways to extend it or change the core functionality of those libraries, sometimes it\u0026rsquo;s better to rethink the approach and question what you need from those libraries. If you need only 20% and end up hacking the rest of 80%, you might get benefits from owning all of the code.\nIf you have any thoughts or questions, please share them, and I will be happy to answer in the comments.\n","date":"15 November 2019","permalink":"/posts/when-open-source-has-less-benefits/","section":"Posts","summary":"Here at Shopify, I work as a Production Engineer on the Jobs team. Our mission is to maintain and improve the background job infrastructure for Shopify Core, which happens to be one of the largest Ruby on Rails applications in the World.","title":"When open source has less benefits"},{"content":"","date":"30 April 2019","permalink":"/tags/redis/","section":"Tags","summary":"","title":" redis"},{"content":"Last year in September I joined the Job Patterns team at Shopify.\nThe mission of the team is to provide a stable platform so that developers can write their background jobs to power one of the biggest e-commerce platforms in the world.\nSince I joined, I have been gathering context around the various components that create the unique Shopify ecosystem.\nTo provide some context, Shopify is a massive Ruby on Rails monolith application and the background job architecture consists of ActiveJob, Resque, and Redis. Besides the functionality that those libraries provide by default, we have created many additional modules that allow developers to define custom behaviour for their jobs: Locking, LockQueue, Concurrency, Retry, Status, and many more.\nAt Shopify, we have many Redis instances; Each instance stores information that belongs to different parts of the platform.\nThis post is going to focus on how we managed to migrate millions of keys from one of our Redis instances to another without downtime or incidents.\nThe module we\u0026rsquo;ll be discussing here is the Locking module. Developers use this module to prevent multiple jobs of the same class with the same arguments to be executed by multiple processes at the same time. It provides the same functionality as unique jobs for Sidekiq.\nBefore enqueuing the job, it checks for the existence of the lock key. If the lock key does not exist, we acquire it until the job is done and finally release it. If the lock key does exist at the time of enqueueing it means that another job already exists, so we do not enqueue the new job.\nImproving performance # At the current growth rate of Shopify, we are looking into multiple ways to optimize the background jobs infrastructure for performance.\nTo reduce load from a single Redis for jobs queues, we plan on deploying more Redis instances so we can multiplex both the enqueue and dequeue operations.\nA blocker for this idea is that we would need to know at all times where the unique locks are stored ü§î.\nWe decided on the solution to move lock keys from the Redis instance holding the queue information to a separate Redis instance. That way, we know at all times where the lock keys are stored unlike job queues that could span across multiple Redis instances in the future.\nWe process hundreds of thousands of jobs per minute, and those jobs are time-sensitive, so stopping the system, migrating the keys and deploying the changes is not a possible solution for us. We, therefore, had to perform the migration without a maintenance window or downtime.\nHow did we manage to achieve this?\nWe devised a 3-step plan that would allow us to do it. All steps required code changes in the application, so the full migration took roughly 2 weeks.\nImplementation # Let\u0026rsquo;s introduce our Locking module. The following is going to be a simplified version of the one currently maintained at Shopify:\nclass Locking AlreadyAcquireLockError = Class.new(StandardError) attr_reader :lock_key, :token def initialize(lock_key, token: SecureRandom.uuid) @lock_key = lock_key @token = token @have_lock = false end def have_lock? @have_lock end def acquire(duration) raise AlreadyAcquireLockError if have_lock? @have_lock = redis.set(key, token, ex: duration, nx: true) end def relase redis.del(key) @have_lock = false end def locked? redis.exists(key) end private def redis Resque.redis end end In the following steps, we will refer to the Redis instance holding the queue information as the jobs Redis (the source of the migration), and the Redis instance holding the locks information as the locks Redis (the destination of the migration).\nFirst Step:\nWe modify the locked? method to check on the locks Redis and then on the resque Redis. With this change, the functionality stays the same, but we introduce the locks Redis as a new dependency.\ndef locked? redises.each do |redis| break(true) if redis.exists(key) end false end private def redis Resque.redis end def redises [Lock.redis, redis] end Second Step:\nWe are going to start acquiring the lock key on the locks Redis. The release method tries to release the lock from the locks Redis instance first, and if not successful, it will try releasing the lock from the Resque Redis instance. The locked? method stays the same as in the first step.\ndef acquire raise AlreadyAcquireLockError if have_lock? @have_lock = lock_redis.set(key, token, ex: duration, nx: true) end def release redises.each do |redis| # redis returns the number of keys deleted if redis.del(key) \u0026gt; 0 @have_lock = false break end end end private def redis Resque.redis end def lock_redis Lock.redis end def redises [lock_redis, redis] end Note: After deploying this change, we monitored the platform for a couple of days to make sure everything was working as expected (meaning, lock keys were being acquired and released without any issue).\nLast Step:\nWe change all the code to make sure that the only Redis instance involved with the Locking module is the locks Redis. All acquiring, releasing and checking actions of the keys have now been migrated over.\nprivate def redis Lock.redis end With these steps, we were able to migrate the lock keys successfully without impacting the platform üéâ üéâ.\nBefore starting the migration we asked ourselves questions like: Would the locks Redis be able to handle the load? Is the locks Redis a single point of failure?\nThe changes weren‚Äôt as straightforward as described above. There were other components involved, many tests to modify and some infrastructure changes to be done in other areas for this to happen but those are out of the scope of the post.\nOf course, there is no simple, one-size-fits-all solution, but I wanted to share our approach with everyone, and hopefully, if you encounter a similar situation this could be of use.\nIf you have any thoughts or questions, please share, and I will be happy to answer in the comments.\n","date":"30 April 2019","permalink":"/posts/migrating-millions-of-redis-keys-without-downtime/","section":"Posts","summary":"Last year in September I joined the Job Patterns team at Shopify.\nThe mission of the team is to provide a stable platform so that developers can write their background jobs to power one of the biggest e-commerce platforms in the world.","title":"Migrating millions of Redis keys without downtime"},{"content":"","date":"23 September 2018","permalink":"/tags/lifestyle/","section":"Tags","summary":"","title":"lifestyle"},{"content":"It has been a while since I blog üò•\nA lot has happened in the last six months.\nI started working for an English company based in London as a remote developer; I always wanted to work with a complete distributed team. The experience was great it gave me the flexibility I was looking for, and I never felt lonely or running a solo mission against the code.\nIs true that some things could have been improved, like the communication channels or how often we would hang out, but hey nothing is perfect.\nThe summer has ended, and now some changes are coming.\nI had the great opportunity to come to Montreal, Canada to work for Shopify as a production engineer. As you can imagine I took the chance without blinking.\nAfter some thoughts about my current situation, I decided to level up my game and start getting more serious with the way I face new opportunities for learn (As I predict there are going to be a lot üéâ with my new role).\nI decided that I will try blogging as much as possible and sharing what I learn in this new stage. That way I\u0026rsquo;m sure I will improve writing skills, and I will have an archive that I can always come back looking for answers. Following this train of thought I will read more books but not only programming books, looks like is an incredible habit that can affect not only your professional life but your personal life as well. Here is an excellent article about that subject.\nI\u0026rsquo;m going to listen more and try not to shout out everything that pops into my head, or at least I\u0026rsquo;m going to think about it twice üßê.\nAlso, I want to learn a new programming language, one that is not similar to Ruby I was thinking maybe Rust or Go that way I can learn new concepts and possibly bring them to my daily job.\nNot to forget to keep helping as much as possible with OSS especially with dry-rb, rom-rb and Hanami but keeping an eye open for new an exciting projects.\nI know the list above is not small or simple to achieve, on top of that there has to be room for social life and daily exercise, I need to find an agenda that works with me. (I will share it once I find out üòÅ)\nI will keep everyone posted.\n","date":"23 September 2018","permalink":"/posts/summer-resolutions_/","section":"Posts","summary":"It has been a while since I blog üò•\nA lot has happened in the last six months.\nI started working for an English company based in London as a remote developer; I always wanted to work with a complete distributed team.","title":"Summer Resolutions 2018"},{"content":"","date":"6 March 2018","permalink":"/tags/grpc/","section":"Tags","summary":"","title":" grpc"},{"content":"So the other day I found an exciting project Anycable that allow using custom WebSocket server within your ruby application. I immediately got hooked up, and I started reading about it, and the first thing that I never heard of it was Grpc.\nGrpc is an Open Source RPC framework developed by Google which uses protocol buffers. RPC (remote procedure call) the idea is that we can call a method on a server as we were calling a local object.\nSo the first thing I did was visit the official site for Grpc and went straight to the ruby section. What I found is a tutorial that is not up to date with the code from the repo at Github, and I found a little hard to follow, so I decided to merely extract the tutorial to my repo and explaining the overview of what I learned.\nPlease, I want to make clear that the majority of the code is identical to the one in the grpc repo but I organized and rename a couple of things, so is easier to understand.\nThe first piece in our puzzle is the definition of our Grpc service, for that we use a file with proto extension.\nIf you never use protocol buffers before do not worry it may sound scary, but it is a pretty simple idea. Inside our proto file, we define the different types that we use both for the client and the server, you can think of them as objects.\nmessage Coordinate { int32 latitude = 1; int32 longitude = 2; } You can even use already defined types inside other types.\nmessage Area { Coordinate lo = 1; Coordinate hi = 2; } There are are many more features in protocol buffers, but I am not going cover them here.\nNow that we have our basic types defined we are going to create our service; you can think of it as our API on our server.\nWe need to define a service and declare the different methods that the clients can call.\nservice RouteGuide { # this will the name of our service } Inside our service, we define the different rpc calls.\nThere are 4 ways a client can communicate with the server:\nThe client sends a request, and the server sends a response, this is the simplest one.\nrpc GetLocation(Coordinate) returns (Location) {}\nThe client sends a request, and the server sends a stream of messages back, then the client reads them.\nrpc ListLocations(Area) returns (stream Location) {}\nThe client sends a stream of messages then the client waits for the server to read them all and send a response.\nrpc RecordRoute(stream Coordinate) returns (RouteSummary) {}\nLast option and more complicated one, bidirectional were both sides send a read-write stream, the two stream works independently so clients and servers can read and write in whatever order they like. The order of messages in each stream is preserved.\nrpc RouteChat(stream RouteNote) returns (stream RouteNote) {}\nThat is all that we need to know. Here is the complete file\nNow we are going to start working on the Ruby implementation of the server and the client.\nWe need these dependencies to read our proto file and transform into something our ruby code could understand\ngem install \u0026#34;grpc\u0026#34; gem install \u0026#34;grpc-tools\u0026#34; Thanks to grpc-tools we can use a command to transform our proto file into a ruby file.\nbundle exec grpc_tools_ruby_protoc That creates files with all the objects that we need to work.\nCreating the server # Let\u0026rsquo;s explain what our server does; It has a Hash database of locations where it stores the latitude and longitude as keys, and the value is the name of that location.\nSo our server can receive a Coordinate (latitude and longitude) and get a Location back with the information.\nIt can receive an Area that is defined between two coordinates and return a list of location within that region.\nIt can receive a stream of coordinates an calculate the route summary between this coordinates.\nTo create the server we need first to create a Handler it has the same contract as we previously defined in our proto file, and we described above, so it has corresponding methods for all the rpc calls we have previously defined\nThanks to the generated files we have access to some classes that help to define our Handler. So we are going to start by creating a class that extends from RouteGuide::Service class generated from the proto file.\nLet\u0026rsquo;s implement the GetLocation contract.\ndef get_location(coordinates, _call) name = DB.find(longitude: coordinates.longitude, latitude: coordinates.latitude) || \u0026#39;\u0026#39; Location.new(coordinates: coordinates, name: name) end The DB is the Hash database that we previously mentioned. So if we read the method it is quite clear what is doing, is receiving a coordinate as an argument, is looking inside the DB for the name of that coordinate and is returning a new Location. Remember that Location is something that we generated from the proto file.\nNow, let\u0026rsquo;s try with the server stream example. The contract said that the server would receive a rectangle and it streams points back to the client. To achieve this, we need to return an Enumerator that yields our points to the client\ndef list_locations(area, _call) Locations.new(area).each end The logic for yielding points is encapsulated inside the Locations you can see the full code here\nLet\u0026rsquo;s see the example when the client sends a stream of points to the server. When the server receives a stream, it gets an Enumerator where it reads all the data.\ndef record_route(call) RecordRoute.new(call).call end On the call object from the arguments, we can use the method each_remote_yield that yield each message sent from the client.\ncall.each_remote_read do |point| # logic inside end You can find the full code here.\nHere is all the code for the Handler class.\nStarting the server # That is the painless part once we have all the logic for the Handler, we just need to create a new instance of GRPC::RpcServer, and we have our server running waiting for clients to send data to it.\nserver = GRPC::RpcServer.new server.add_http2_port(\u0026#34;0.0.0.0:50051\u0026#34;, :this_port_is_insecure) server.handle(Handler.new) server.run_till_terminated Creating the client # When dealing with client code, we need to create what is called a stub it has all the method that we have defined in our service route_guide such as get_location, list_locations, record_route, basically is the way we communicate with the server.\nstub = Routeguide::RouteGuide::Stub.new(\u0026#34;localhost:50051\u0026#34;, :this_channel_is_insecure) Let\u0026rsquo;s communicate with the server to get a feature based on a coordinate; we need to send a Coordinate to the server.\npoint = Coordinate.new(latitude: 409_146_138, longitude: -746_188_906) With that, we can call get_location passing the coordinate and expect to have a response from the server.\nresponse = stub.get_location(coordinate) response.name # =\u0026gt; \u0026#39;Berkshire Valley Management Area Trail, Jefferson, NJ, USA\u0026#39; response.coordinates # =\u0026gt; \u0026lt;Routeguide::Coordinate: latitude: 409146138, longitude: -746188906\u0026gt; Let\u0026rsquo;s look at an example where the server returns as a stream of data. The server returns an Enumerator, and we can loop over it reading the multiple responses, it feels like executing a method from a local object.\nrectangle = Area.new( lo: Coordinate.new(latitude: 400_000_000, longitude: -750_000_000), hi: Coordinate.new(latitude: 420_000_000, longitude: -730_000_000)) responses = stub.list_locations(area) responses.each do |r| puts \u0026#34;- found \u0026#39;#{r.name}\u0026#39; at #{r.coordinates.inspect}\u0026#34; end Lastly, let\u0026rsquo;s look an example when the client sends a stream of data to the server; it works similarly as the server implementation it should send an Enumerator which yield each message to the server.\nclass RandomRoute attr_reader :size def initialize(size) @size = size end def each return enum_for(:each) unless block_given? size.times do feature = DB.rand point = create_point(feature[:location]) yield point end end private def create_point(location) Routeguide::Coordinate.new(Hash[location.each_pair.map { |k, v| [k.to_sym, v] }]) end end points_on_route = 10 # arbitrary request = RandomRoute.new(points_on_route) response = stub.record_route(request.each) puts \u0026#34;summary: #{response.inspect}\u0026#34; Our class RandomRoute encapsulate the logic for creating an Enumerator using the Kernel method enum_for there is an excellent article that explain it more in depth.\nWith all of this, we just created a Grpc Server and a Client that communicate with each other.\nI have created a repo with all the code so you can have a look.\nIf you have any thoughts or questions, please share, and I will be happy to answer in the comments.\nThank you for reading I know it has been a long journey, but I hope you have learned something new today.\n","date":"6 March 2018","permalink":"/posts/grpc-tutorial-with-ruby/","section":"Posts","summary":"So the other day I found an exciting project Anycable that allow using custom WebSocket server within your ruby application. I immediately got hooked up, and I started reading about it, and the first thing that I never heard of it was Grpc.","title":"Grpc Tutorial with ruby"},{"content":"","date":"3 November 2017","permalink":"/tags/functional-programming/","section":"Tags","summary":"","title":" functional programming"},{"content":"Revised by Andy Holland\nLately, there has been a significant change in the industry towards functional programming, new languages have appeared: Elixir, Scala, Elm.\nWith all this new hype I decided to give a try to some of them, and I have to say that they are really cool, but wether I like it at work I mostly use ruby. Not that I complain or anything but is exciting to be able to play with the new kid on the block.\nAfter some time playing with a new functional programming languages, I have noticed that Ruby has some similarities with them.\nI\u0026rsquo;m not going to say that ruby is a FP language nor that Matz the creator is incorrect.\nTo quote Matz words from an interview with O\u0026rsquo;Reilly.\nI wanted a scripting language that was more powerful than Perl, and more object-oriented than Python.\nSo Ruby is an object-oriented language - that\u0026rsquo;s is for sure - but I wanted to share my idea that ruby is a multipurpose language.\nAccording to Wikipedia for a programming language to be considered Functional it needs to have:\nFirst-class and higher-order functions Pure functions Recursion Strict versus non-strict evaluation Type systems Currying Lazy Evaluation We are going to explore some of the concepts with Ruby üíé\nHigher-order functions # takes one or more functions as arguments returns a function as its result In ruby, there are examples everywhere which show that ruby has support for Higher-order functions.\nLet\u0026rsquo;s look at a well-known ruby method each.\n[1,2,3,4].each { |x| puts x*x } #=\u0026gt; [1,4,9,16] We can consider the block as passing a function as argument\nTo make the case more clear, you can write the same example using lambdas.\nsquare = -\u0026gt; { |x| puts x*x } [1,2,3,4].each(\u0026amp;square) #=\u0026gt; [1,4,9,16] Many of ruby-core methods take a block or function as argument each, map, select.\nAs for functions that return other functions as not that common in ruby but doesn\u0026rsquo;t mean we can\u0026rsquo;t do it.\ndef adder(a, b) lambda { a + b } end adder_fn = adder(1, 2) adder_fn.call # =\u0026gt; 3 First Class Functions and Support for Lambdas # Ruby has support for multiple types of functions; lambdas and procs, there are shuttle differences between them, and we will need a whole post about it, but instead, there are many significant resources out there explaining the differences articles. How I like to think about them is as functions that can you stored in variables:\nadd = -\u0026gt; (x,y) { x + y } multiply = -\u0026gt; (x,y) { x * y } One interesting pattern is the policy pattern that allows you to have a function execute the same tasks but depending on the business logic the callbacks for success or failure can be configured:\ndef create_record(attributes, success_policy, failure_policy) if Record.create(attributes) success_policy.call else failure_policy.call end end success_policy = -\u0026gt; () { send_email } failure_policy = -\u0026gt; () { puts \u0026#39;something went wrong\u0026#39; } create_record({name: \u0026#39;John\u0026#39;}, succes_policy, failure_policy) One thing that is not that common in ruby is storing method inside variables, using the method method, we can store them and pass it to functions as if it were a proc or a lambda.\nThere is an excellent video from RubyTapas that cover this topic very well.\nFor now, I let you a small example:\ndef hello yield end def hi \u0026#34;hi there.\u0026#34; end hello \u0026amp;method(:hi) Currying # Currying means to partially apply a function, here are a couple of definitions:\nPartial function application is calling a function with some number of arguments, to get a function back that will take that many fewer arguments. Currying is taking a function that takes n arguments, and splitting it into n functions that take one argument. In ruby land; is not very common to use this technique, but this allows us to have small and reusable functions that can be easy to use and understood while you read your code.\nSince Ruby 1.9, the Proc class have the method: #curry, that allow us to implement both options.\nLet\u0026rsquo;s see some examples.\ndb_operation = lambda do |db_adapter, operation, record| db_adapter.send(operation, record) end create_db_operation = db_operation.curry(DB, :create) delete_db_operation = db_operation.curry(DB, :delete) create_db_operation.(maria_record) delete_db_operation.(maria_record) A nice plus is that working with this small functions your code becomes much easier to test.\nLazy evaluation # First of all, I encourage to check this blog post from Pat Shaughnessy\nLazy evaluation allows us to consume data on demand, instead of evaluating everything up front.\nLets look at some examples:\nrange = 1..Float::INFINITY range.each { |x| x*x }.take(10) #=\u0026gt; endless loop! # Using lazy range = 1..Float::INFINITY range.lazy.each { |x| x*x }.take(10) #=\u0026gt; [1,4,9,16,25,336,49,64,81,100] Without the lazy it tries to consume all the elements and transform them, ending in an endless loop but the second example uses the lazy evaluation allowing to collect only the data that need.\nThis technique is advantageous when we are dealing with an enormous amount of data, and we do not want to transform all of them at once but instead only on demand.\nType system # We all know that ruby is a dynamic language with great introspection capabilities, and doesn\u0026rsquo;t have a type system.\nProbably one of the reasons everyone loves ruby is due to these specifications, where we are allowed to do want we want. But having that freedom of choice, we tend to end with profoundly entangled and error-prone applications.\nI\u0026rsquo;m not saying not to use ruby, but some type system that allows us to have warranties of want sort of data are we working with would be fantastic.\nDry-types to the rescue \\o/.\nTalking about dry-types would be out of scope for this post and probably requires one itself üòâ but just to let you know: if you are looking for a valuable option for your application, there is one.\nPure functions # A pure function is a function which:\nGiven the same input, will always return the same output. Produces no side effects. Having pure functions will give us a lot of benefits, the first one that comes to my mind is parallel processing.\nPure functions are also easy to understand, refactor and move around, making our application less error prone.\nAnd going to show a straightforward example\ndef double(number) number * 2 end No matter what if we introduce the same input it will return the same output.\nRuby allow us to have mutable state, so is up to us to change how we write our function in a way that is pure.\nIf you have any thoughts or questions, please share and I‚Äôll be happy to answer in the comments.\n","date":"3 November 2017","permalink":"/posts/functional-programming-aspects-of-the-ruby-language/","section":"Posts","summary":"Revised by Andy Holland\nLately, there has been a significant change in the industry towards functional programming, new languages have appeared: Elixir, Scala, Elm.\nWith all this new hype I decided to give a try to some of them, and I have to say that they are really cool, but wether I like it at work I mostly use ruby.","title":"Functional programming aspects of the Ruby language"},{"content":"","date":"17 July 2017","permalink":"/tags/dry-rb/","section":"Tags","summary":"","title":" dry-rb"},{"content":"","date":"17 July 2017","permalink":"/tags/orm/","section":"Tags","summary":"","title":" ORM"},{"content":"","date":"17 July 2017","permalink":"/tags/rom-rb/","section":"Tags","summary":"","title":" rom-rb"},{"content":"Following with my previous post, Dry-web-roda part 1, I have decided to create my own small website to keep track of all the things I learn throughout the day.\nYes, I know, another Today I Learned Website üòì - til_web, but this time I started with the persistence layer and I wanted to share my experience with you.\nFirst of all, we will need dry-web-roda that will behave as our web application stack. When creating a new project with it, we have two options regarding the architecture point of view of our application: umbrella or flat.\nUmbrella means that our functionality will be divided into sub-apps - for example the public site and the admin site.\nFlat is a simpler architecture with a single module for the entire app.\nIn my app I decided to use the flat option for simplicity at the beginning, but in the future I plan to move to sub-apps.\nLet\u0026rsquo;s start by creating our new application by running the new command:\n$ dry-web-roda new til_web --arch=flat` which will generate the file structure that we will need.\nToday, we will focus mostly on the persistence layer.\nTo start we have to create our new development database; note that the name will be extracted from the name of the project (in this case til_web_development). All the information regarding the ENV is located in the .env file in the root of the project.\nAt the moment we only support PostgreSQL (gem pg) as the database storage. If you don\u0026rsquo;t have it installed, I find it really easy to use the postgres app to reduce the burden.\nTo create the database we can use some of the commands that the postgres app installed for us:\n$ create_db -h localhost til_web_development` Let\u0026rsquo;s continue by creating some migrations files to start setting up the schema of our database. dry-web-roda uses rom-rb as its persistence toolkit, this allows us to have a clean separation of responsibilities and make an app that remains easy to change.\nWe can use the rake task provided to create a new migration file:\n$ bundle exec rake db:create_migration[add_author]\nwhich will create a new file inside our db/migrate folder.\nRom uses sequel for the database migration engine.\nFor any aspect related to migrations, please refer to the Sequel documentation\nWe continue by creating a table and adding some fields to it.\nROM::SQL.migration do change do create_table :tils do primary_key :id column :title, String, null: false column :text, \u0026#39;text\u0026#39;, null: false column :created_at, DateTime, null: false, default: Sequel::CURRENT_TIMESTAMP column :updated_at, DateTime, null: false, default: Sequel::CURRENT_TIMESTAMP end end end Running $ bundle exec rake db:migrate will create our new table.\nNow that we have created a database table we can start creating some Relations, Commands and Repositories all of this concepts belongs to rom-rb.\nInside our lib/persistence folder we have relations and commands folders.\nRelations are the interface to a particular collection in our data source, which in SQL terms is either a table or a view. We could think of them as our models.\nmodule Persistence module Relations class Tils \u0026lt; ROM::Relation[:sql] schema(:tils) do attribute :id, Types::Serial attribute :title, Types::Strict::String attribute :text, Types::Strict::String end def by_id(id) where(id: id) end end end end We need to define a schema and some composable, reusable, query methods to return filtered results from our database table. For example by_id(id).\nLet\u0026rsquo;s continue by creating a new command.\nmodule Persistence module Commands class CreateTil \u0026lt; ROM::Commands::Create[:sql] relation :tils register_as :create result :one end end end Commands are used to write to our database. By default ROM comes with create, update and delete, but you can create your custom ones by following the commands guide.\nFinally let\u0026rsquo;s create our Repository. Repository works as the main interface to interact with our Database.\nFor my project I created the folder repositories inside the til_web, that would use auto_register from dry-system to register them in my container.\nrequire \u0026#39;til_web/repository\u0026#39; module TilWeb module Repositories class Tils \u0026lt; TilWeb::Repository[:tils] def [](id) tils.by_id(id).one! end end end end Our last step is to create some sample data so we can play with it in the console.\nWe open our sample_data.rb file and change it to:\n# need the application to be booted in order to access the container. require_relative \u0026#39;../system/boot\u0026#39; require \u0026#39;faker\u0026#39; def create_til(attrs) # this line is use to access the rom container, that is created at the booting process # of the application. # inside the `system/boot/rom.rb` TilWeb::Container[\u0026#39;persistence.rom\u0026#39;].commands[:tils][:create].call(attrs) end 20.times do create_til( title: Faker::Lorem.sentence(4), text: Faker::Lorem.paragraph(5) ) end To populate the database we use $ bundle exec rake db:sample_data.\nNow accessing the console, by typing $ bin/console allows us to check that everything has been stored in the database.\nTo access the repository we type TilWeb::Conatiner['repositories.tils'] which will return an instance of TilWeb::Repositories::Tils with all the dependencies that it needs.\nLastly we can check that there is data in the database by writing TilWeb::Container['repositories.tils'][1]\n\u0026gt; TilWeb::Container[\u0026#39;repositories.tils\u0026#39;][1] =\u0026gt; #\u0026lt;ROM::Struct::Til id=1 title=\u0026#34;Illo qui laborum dolores.\u0026#34; text=\u0026#34;Illum laboriosam adipisci incidunt. Ad aliquam ratione non adipisci quia velit. Veritatis eum minus ut quod mollitia sit. Ea tenetur aliquam fugit mollitia. Rerum ratione et dignissimos a et enim necessitatibus. Animi nesciunt qui rerum voluptatem ipsum atque ad.\u0026#34;\u0026gt; And thats it üéâ.\nI know some concepts are quite different than what we are used to work with, and I could keep talking about them, but this post is getting quite long so I will stop here for now.\nIf you have any thoughts or questions, please share and I‚Äôll be happy to answer in the comments.\nAlso here are some extra resources regarding rom-rb at it\u0026rsquo;s benefits.\nA conversational introduction to rom-rb\nConversational rom-rb, part 2: types, associations, and update commands\nThank you for reading this far!\n","date":"17 July 2017","permalink":"/posts/dry-web-roda-for-rails-developers-part_ii-persistence/","section":"Posts","summary":"Following with my previous post, Dry-web-roda part 1, I have decided to create my own small website to keep track of all the things I learn throughout the day.\nYes, I know, another Today I Learned Website üòì - til_web, but this time I started with the persistence layer and I wanted to share my experience with you.","title":"Dry-web-roda for Rails Developers Part II (Persistence)"},{"content":"Revised by Piotr Solnica and Andy Holland\nLately, I have been playing around and contributing to the great ecosystem of dry-rb, first of all, I have to say the community is absolutely fantastic, super supportive and eager to welcome many new contributors.\nFirst I will like to thank Piotr Solnica, Andy Holland, Tim Riley and Nikita Shilnikov - they have been really helpful and patient with my many questions.\nYesterday I decided to start playing around with a gem call dry-web-roda this small framework aims to provide an alternative to building web apps using ruby, with the use of small libraries such as dry-view, dry-container, dry-transaction, roda, rom and many more; the help you build clearer, flexible and more maintainable code.\nThe post tries to create a bridge for Rails Developers and encourage them to try these new alternatives, that will bring joy and fresh concepts for building web apps with ruby.\nAfter installing the gem we can create a sample app by typing dry-web-roda new github_stalker --arch=flat- this will create the file structure.\n‚îú‚îÄ‚îÄ bin ‚îú‚îÄ‚îÄ config ‚îú‚îÄ‚îÄ db ‚îú‚îÄ‚îÄ lib ‚îÇ¬†‚îú‚îÄ‚îÄ github_stalker ‚îÇ¬†‚îÇ¬†‚îî‚îÄ‚îÄ views ‚îÇ¬†‚îî‚îÄ‚îÄ persistence ‚îÇ¬†‚îú‚îÄ‚îÄ commands ‚îÇ¬†‚îî‚îÄ‚îÄ relations ‚îú‚îÄ‚îÄ log ‚îú‚îÄ‚îÄ spec ‚îÇ¬†‚îî‚îÄ‚îÄ support ‚îÇ¬†‚îî‚îÄ‚îÄ db ‚îú‚îÄ‚îÄ system ‚îÇ¬†‚îú‚îÄ‚îÄ boot ‚îÇ¬†‚îî‚îÄ‚îÄ github_stalker ‚îú‚îÄ‚îÄ transactions ‚îî‚îÄ‚îÄ web ‚îú‚îÄ‚îÄ routes ‚îî‚îÄ‚îÄ templates ‚îî‚îÄ‚îÄ layouts At first the structure is quite different from what we are used to in a typical Rails app, but I will try my best to explain it.\nFirst, the system folder is where all the configuration lives, we can think of them as our initializers, this will be the entry point of our application. There are many small libraries involved to make everything work, that I can not go into detail in just one post, I will try cover all of them in a series of posts.\n‚îú‚îÄ‚îÄ system ‚îú‚îÄ‚îÄ boot ‚îÇ¬†‚îú‚îÄ‚îÄ monitor.rb ‚îÇ¬†‚îú‚îÄ‚îÄ rom.rb ‚îÇ¬†‚îî‚îÄ‚îÄ view.rb ‚îú‚îÄ‚îÄ boot.rb ‚îî‚îÄ‚îÄ github_stalker ‚îú‚îÄ‚îÄ application.rb ‚îú‚îÄ‚îÄ container.rb ‚îú‚îÄ‚îÄ import.rb ‚îú‚îÄ‚îÄ repository.rb ‚îú‚îÄ‚îÄ settings.rb ‚îú‚îÄ‚îÄ transactions.rb ‚îú‚îÄ‚îÄ view_context.rb ‚îî‚îÄ‚îÄ view_controller.rb We will start with application.rb, this file contains all the configuration regarding routes, container and plugins to be use with roda.\nrequire \u0026#34;dry/web/roda/application\u0026#34; require_relative \u0026#34;container\u0026#34; module GithubStalker class Application \u0026lt; Dry::Web::Roda::Application configure do |config| config.container = Container config.routes = \u0026#34;web/routes\u0026#34;.freeze end opts[:root] = Pathname(__FILE__).join(\u0026#34;../..\u0026#34;).realpath.dirname use Rack::Session::Cookie, key: \u0026#34;github_stalker.session\u0026#34;, secret: GithubStalker::Container.settings.session_secret plugin :csrf, raise: true plugin :flash plugin :dry_view route do |r| r.multi_route r.root do r.view \u0026#34;welcome\u0026#34; end end load_routes! end end What is a container? I\u0026rsquo;m going to bring the words from the official website dry-container is a simple, thread-safe container, intended to be one half of the implementation of an IoC container or how I understand it a container ‚Äúgives you access to the objects that make up your application‚Äù.\nRoda (the router) is a Routing Tree Web Toolkit I will not go into much detail since I\u0026rsquo;m really new to it.\nFollowing is the container.rb and import.rb, which in my opinion is where all the magic happens, thanks to dry-container and dry-auto_inject. This holds the configuration for loading the files for our application, more or less like auto_load_path of Rails, but only using ruby methods and variables require and $LOAD_PATH.\nrequire \u0026#34;dry/web/umbrella\u0026#34; require_relative \u0026#34;settings\u0026#34; module GithubStalker class Container \u0026lt; Dry::Web::Umbrella configure do config.name = :github_stalker config.default_namespace = \u0026#34;github_stalker\u0026#34; config.settings_loader = GithubStalker::Settings config.listeners = true config.auto_register = %w[ lib/github_stalker ] end load_paths! \u0026#34;lib\u0026#34;, \u0026#34;system\u0026#34; def self.settings config.settings end end end At first sight, we see some configuration for name, namespace and some auto_register, this will register all the files inside our lib/github_stalker folder in your container, following the convention from the file structure, so for example\n‚îú‚îÄ‚îÄ lib ‚îú‚îÄ‚îÄ github_stalker ‚îú‚îÄ‚îÄ github ‚îÇ¬†‚îú‚îÄ‚îÄ client.rb # will register inside our container under the name github.client ‚îÇ¬†‚îú‚îÄ‚îÄ fetch_gists.rb # github.fetch_gists ‚îÇ¬†‚îî‚îÄ‚îÄ fetch_info.rb # github.fetch_info ‚îî‚îÄ‚îÄ users ‚îî‚îÄ‚îÄ validate_input.rb # users.validate_input And thanks to dry-auto_inject, all these files will be lazily loaded as required, making it really efficient.\nrequire \u0026#34;github_stalker/import\u0026#34; module GithubStalker module Github class FetchGists include GithubStalker::Import[\u0026#39;github.client\u0026#39;] # at the instance level we will have access to `client` def call(input) client.gists(input) end end end end Well I think this post is getting too long and I don‚Äôt want to take more of your time. Thank you for reading it. I will keep creating more posts explaining the rest of the structure and libraries involved in dry-rb - they are great and bring a fresh view in the ruby world.\nAll the above example were taken from an example app I built using dry-web-roda if you want to check the code please follow this repo\nIf you have any thoughts or questions, please share and I‚Äôll be happy to answer in the comments.\n","date":"28 May 2017","permalink":"/posts/dry-web-roda-for-rails-developers_part_i/","section":"Posts","summary":"Revised by Piotr Solnica and Andy Holland\nLately, I have been playing around and contributing to the great ecosystem of dry-rb, first of all, I have to say the community is absolutely fantastic, super supportive and eager to welcome many new contributors.","title":"Dry-web-roda for Rails Developers Part I"},{"content":"","date":"17 October 2016","permalink":"/tags/rvm/","section":"Tags","summary":"","title":" rvm"},{"content":"","date":"17 October 2016","permalink":"/tags/workflow/","section":"Tags","summary":"","title":" workflow"},{"content":"I took me some time, to figure out how to correctly setup every project I worked on, not that I work in tons of projects, but now that I have a better understanding of how to setup, it makes more sense to me, at least.\nRVM # So RVM or Ruby Version Manager, allow to install different ruby version on the same machine without them collision it.\nWhen RVM installs a new version of ruby it will create a new folder inside the ~/.rvm/gems folder with the name of the ruby version, that way when installing different ruby version each of them will have their own folder, each folder containing the next structure\ndrwxr-xr-x 11 ‚Ä¶‚Ä¶‚Ä¶ staff 374 Sep 13 23:10 . drwxr-xr-x 13 ‚Ä¶‚Ä¶‚Ä¶ staff 442 Oct 17 15:37 .. drwxr-xr-x 5 ‚Ä¶‚Ä¶‚Ä¶ staff 170 Sep 13 23:10 bin drwxr-xr-x 2 ‚Ä¶‚Ä¶‚Ä¶ staff 68 Sep 13 23:10 build_info drwxr-xr-x 4 ‚Ä¶‚Ä¶‚Ä¶ staff 136 Sep 13 23:10 cache drwxr-xr-x 2 ‚Ä¶‚Ä¶‚Ä¶ staff 68 Sep 13 23:10 doc -rw-r--r-- 1 ‚Ä¶‚Ä¶‚Ä¶ staff 468 Jul 30 17:45 environment drwxr-xr-x 2 ‚Ä¶‚Ä¶‚Ä¶ staff 68 Sep 13 23:10 extensions drwxr-xr-x 4 ‚Ä¶‚Ä¶‚Ä¶ staff 136 Sep 13 23:10 gems drwxr-xr-x 4 ‚Ä¶‚Ä¶‚Ä¶ staff 136 Sep 13 23:10 specifications drwxr-xr-x 13 ‚Ä¶‚Ä¶‚Ä¶ staff 442 Sep 13 23:10 wrappers When using that version of ruby, all the gems installed via gem install ... will be installed in the gems folder, that way we can have different version of the same gem in the different ruby version, in our computer.\nRVM allow to specify which ruby version are we using when cd inside a project, with a special file .ruby-version. This file will have the ruby version, you can create it manually or tell rvm to do it for you with this command rvm --create --ruby-version ruby-2.3.3 this will create the .ruby-version file.\nGemsets # When having the same ruby version for multiple projects, could create some conflicts, because we have a different version of nokogiri in both projects, to avoid conflict error, we have to use bundle exec ... to use the version specify by the Gemfile.\nWe can avoid this tedious extra typing by creating a different gemset for each project, and within each gemset all the gems that the project need. So every time we create a new gemset a new folder is added to ~/.rvm/gems/#{ruby-version}@#{gemset} so with this we completely avoid conflicts.\nAnother good thing is when finishing working on the project, we can delete all the gems from that project just by deleting the gemset completely by typing rvm gemset delete #{gemset}\nAs well as the ruby version, RVM can automatically use a gemset by specifying with the file .ruby-gemset\nWorkflow # When I start on a new project, I create a ruby-version and a ruby-gemset file, and install all the gems I need for that project.\nThere is a great command that will create both files for us, let\u0026rsquo;s imagine the ruby version is 2.3.3 and the project is called test_rvm, so I would like to create a gemset for this project, just by typing rvm use --create ruby-2.3.3@test_rvm\nAnother cool thing is that for every ruby version RVM automatically created a global gemset, which all gemsets for that ruby version will share, so before creating a new gemset for that ruby version I make sure that I have installed bundler.\nrvm use global gem install bundler This way I don\u0026rsquo;t have to install in every gemset.\nSo this is my normal workflow, any idea of how to improve it, or if I\u0026rsquo;m doing something wrong. Please just let me know.\n","date":"17 October 2016","permalink":"/posts/my-setup-with-rvm/","section":"Posts","summary":"I took me some time, to figure out how to correctly setup every project I worked on, not that I work in tons of projects, but now that I have a better understanding of how to setup, it makes more sense to me, at least.","title":"My Setup with rvm, gemsets and bundler"},{"content":"","date":"18 September 2016","permalink":"/tags/javascript/","section":"Tags","summary":"","title":" JavaScript"},{"content":"","date":"18 September 2016","permalink":"/tags/react/","section":"Tags","summary":"","title":"React"},{"content":"This is not going to be another post describing React and what is good or what is bad about it, I\u0026rsquo;m just learning it, and part of the learning process I decided that I will write a blog post for helping me maintain this new concepts. I will avoid many concepts, like how to create a project for importing all the libraries, I will create another post regarding that topic.\nComponent # The basic idea behind a component, is that is a reusable piece of code, every component has to have a render function that returns the actual component, in this examples I\u0026rsquo;ll be using JSX, so if you want to check it JSX in Depth, this basically lets us write some sort of html inside our JavaScript file, that when compiled it will look more Reactable.\nvar Nav; // Input (JSX): var app = \u0026lt;Nav color=\u0026#34;blue\u0026#34; /\u0026gt;; // Output (JS): var app = React.createElement(Nav, {color:\u0026#34;blue\u0026#34;}); Back to our Component lets start with a simple one:\nclass Example extends React.Component { render(){ return( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt; Hello \u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ) } } So this is our initial component, to make use of it, we will have to tell React to render it in the DOM.\nReactDOM.render(\u0026lt;Example/\u0026gt;, document.getElementById(\u0026#39;app\u0026#39;)) So now our component has been render inside our \u0026lt;div id=\u0026quot;app\u0026quot;\u0026gt;\u0026lt;/div\u0026gt;.\nBut this isn\u0026rsquo;t really useful, we could achieve the same thing with plain html, wait there is more to it.\nProps # Every component has it\u0026rsquo;s own props, that can be access from inside the component, and that we can pass it from outside the component, just like arguments to a function. To keep the example clear I will just pass the text that I want to display inside.\nReactDOM.render(\u0026lt;Example text=\u0026#34;Hello from the props\u0026#34;/\u0026gt;, document.getElementById(\u0026#39;app\u0026#39;)) To access it\u0026rsquo;s props we can use this.props inside our component.\nclass Example extends React.Component { render(){ return( \u0026lt;div\u0026gt; \u0026lt;p\u0026gt;{this.props.text}\u0026lt;/p\u0026gt; \u0026lt;/div\u0026gt; ) } } Ok let\u0026rsquo;s recap, we have passed the prop text to our component, and to access it we use this.props.text, but what with the {}. To interpolate it\u0026rsquo;s value inside the render function, we need to surrounded our prop with it.\nNow the component can have dynamic content display in the page. But what happen if you forget to include the text props in the component, do not worry we have defaultProps.\nclass Example extends React.Component { ... } Example.defaultProps = { text: \u0026#39;Using defaults\u0026#39; } This way React has our back.\nState # This is another interesting concept, the state is a collection of values manage by our component. Modifying this values will trigger a new render of our component, but I will talk more in-depth about the render life-cycle in the next post.\nTo setup the states values we have to use the constructor function.\nclass Example extends React.Componet { constructor(){ super(); this.state = { text: \u0026#39;this is from the state\u0026#39; } } render(){ ... } } Now we can use the state with this.state.text, but the state without the a way of modifying it is no use, so to do that we have to use this.setState({}) this will change the state and trigger a new render of the component with the new state.\nTo get something out of this we are going to build a component that will show the text of the state, but we will be able to changed when typing inside a input. We will make use of DOM Event Listeners in a Component.\nSo to make this example work, we will have to hook to an event onChange that will trigger a function that will update the state.\nclass Example extends React.Component { constructor(){ super(); this.state = { txt: \u0026#39;this is the state txt\u0026#39; } } update(e){ this.setState({txt: e.target.value}) } render(){ return ( \u0026lt;div\u0026gt; \u0026lt;input type=\u0026#34;text\u0026#34; onChange={this.update.bind(this)} /\u0026gt; \u0026lt;h1\u0026gt;{this.state.txt}\u0026lt;/h1\u0026gt; \u0026lt;/div\u0026gt; ); } } ReactDOM.render(\u0026lt;Example /\u0026gt;,document.getElementById(\u0026#39;app\u0026#39;)); This simple post is getting quite long for just explaining the basic. So will leave here a life example so you can play with.\nJS Bin on jsbin.com\nIn the next post I will get more in the DOM Events, the state, render life-cycle and more concepts that I will be learningthis week.\n","date":"18 September 2016","permalink":"/posts/react-back-to-basics/","section":"Posts","summary":"This is not going to be another post describing React and what is good or what is bad about it, I\u0026rsquo;m just learning it, and part of the learning process I decided that I will write a blog post for helping me maintain this new concepts.","title":"React back to basics"},{"content":"After a long vacation, I came with a lot of energy and new goals for the new year.\nSo I decided that I\u0026rsquo;m going to start making things right, been a developer is not always easy, you have to continuosly update your knowledge and keep practicing even outside office hours. Don\u0026rsquo;t get me wrong I love coding but there are days or weeks that I\u0026rsquo;m more lazy than usual.\nTo solve this situation I\u0026rsquo;m going to start using somo Todo App for managing my free time, and create a timetible of small but doable goals.\nHere is a list of some of my goals:\nBlog once a week:\nThe post don\u0026rsquo;t need to be extremly technical, but the idea is to blog about something that I learn new every week, maybe is a new Design Pattern or just a new way of dealing with stress. Learn Elixir.\nLearn React.\nLearn new way of improve my ruby skills:\nLately I\u0026rsquo;ve been reading a lot about using Functional Programming with OO principles. So I have an eye on the great work of Piotr Solnica. I will try to create a couple of gems following this new dry-rb concepts. So hope you guys come join me in this new year of goals and challenges.\n","date":"6 September 2016","permalink":"/posts/back-from-summer-resolution/","section":"Posts","summary":"After a long vacation, I came with a lot of energy and new goals for the new year.\nSo I decided that I\u0026rsquo;m going to start making things right, been a developer is not always easy, you have to continuosly update your knowledge and keep practicing even outside office hours.","title":"Back from summer resolution"},{"content":"","date":"17 January 2016","permalink":"/tags/test/","section":"Tags","summary":"","title":" test"},{"content":"In the last couple of weeks I have been working, with a little project of my own. I always love Command Line Tools, I don\u0026rsquo;t know what they have but using them make feel more like a Hackers or someone that actually know what he is doing.\nSo I decided to build one, with the help of a gem called Thor, which by the way is a great gem, that help you build your CLI really easy.\nCodewars provided a great service by letting us the programmer improve our coding skills, I decide to build a CLI to interact with it.\nProbably I will write a post in future about creating a CLI but for now I want to focus on test.\nMy project is called Codewars_Cli, any one interested, is open for suggestions and pull requests.\nTesting # In my day to day I use Rspec for testing, so the idea of using Cucumber really strike as a chance to learn a little more about this testing framework.\nWihch is focus on Behavior Driven Development.\nAruba # Aruba is a great extension either for Rspec and Cucumber that makes testing command-lines tools meanigful, easy and fun. It makes easy to manipulate the file system and the process envarioment, automatically reset state of file system.\nConfiguration # First inside the features/support folder create a env.rb to load aruba and your_application\nrequire \u0026#39;your_library_under_test\u0026#39; require \u0026#39;aruba/cucumber\u0026#39; Now we are ready to start testing our application. By default Aruba will create a folder tmp/aruba where will perform its operations, you can change that in the env.rb with some hooks that Aruba provide.\nBefore do @dirs = [\u0026#39;tmp/my_work\u0026#39;] end For a list of all the available configuration README\nI\u0026rsquo;m going to focus on testing my config commands. Normally this command will involve manipulating a config file store in your HOME folder.\nIf we don\u0026rsquo;t want our test to actually modify that file, aruba can mock our config file as well.\nFeature test example from my small project.\nFeature: Hability to store configuration settings Background: Given a mocked home directory Scenario: Setup the apikey Given the config file do not exists When I run `codewars config api_key test_api` Then the output should contain \u0026#34;Updating config file with api_key: test_api\u0026#34; And the config file contain: \u0026#34;\u0026#34;\u0026#34; :api_key: test_api :language: \u0026#39;\u0026#39; :folder: \u0026#39;\u0026#39; \u0026#34;\u0026#34;\u0026#34; As you can see is really easy with aruba to achieve that.\nAlso I have declare some step_definitions:\nGiven(/^the config file with:$/) do |string| step \u0026#39;a file \u0026#34;~/.codewars.rc.yml\u0026#34; with:\u0026#39;, string end Given(/^the config file do not exists$/) do step \u0026#39;a file \u0026#34;~/.codewars.rc.yml\u0026#34; does not exist\u0026#39; end Then(/^the config file contain:$/) do |string| step \u0026#39;the file \u0026#34;~/.codewars.rc.yml\u0026#34; should contain:\u0026#39;, string end To help me test. There are many more methods that aruba bring us like cd into folder, create files, delete them etc\u0026hellip; Here is another great resource about it Getting Started\nStubbing External Services # In my case my application depends on an external service, so I don\u0026rsquo;t want my test to actually make any real request, that would result in a slower test suite.\nI usually use webmock or VCR to stub my requests.\nAruba execute the command under test in a new child process, that it makes them slower and complicated to mock components. But there is a way to make the test run in the same process.\nFirst we have to wrap our application, and execute the wrapper instead.\nThis is my bin file before introducing the wrapper class:\n!/usr/bin/env ruby -U require \u0026#39;codewars_cli\u0026#39; CodewarsCli::Cli.start(ARGV) After:\n#!/usr/bin/env ruby -U lib = File.expand_path(\u0026#39;../../lib\u0026#39;, __FILE__) $LOAD_PATH.unshift(lib) unless $LOAD_PATH.include?(lib) require \u0026#39;codewars_cli/runner\u0026#39; CodewarsCli::Runner.new(ARGV.dup).execute! CodewarsCli::Runner the wrapper class has to respond to execute!\nNow we have to modify the the env.rb inside our features/support folder.\nrequire \u0026#39;codewars_cli/runner\u0026#39; require \u0026#39;aruba/cucumber\u0026#39; require \u0026#39;aruba/in_process\u0026#39; Aruba.configure do |config| config.command_launcher = :in_process config.main_class = CodewarsCli::Runner end We have added aruba/in_process and pass some configuration to tell aruba to run the test in the same process.\nNow to create our wrapper CodewarsCli::Runner\nrequire \u0026#39;codewars_cli/cli\u0026#39; module CodewarsCli class Runner # Allow everything fun to be injected from the outside while defaulting to normal implementations. def initialize(argv, stdin = STDIN, stdout = STDOUT, stderr = STDERR, kernel = Kernel) @argv, @stdin, @stdout, @stderr, @kernel = argv, stdin, stdout, stderr, kernel end def execute! exit_code = begin # Thor accesses these streams directly rather than letting them be injected, so we replace them... $stderr = @stderr $stdin = @stdin $stdout = @stdout # Run our normal Thor app the way we know and love. CodewarsCli::Cli.start(@argv) # Thor::Base#start does not have a return value, assume success if no exception is raised. 0 rescue StandardError =\u0026gt; e # The ruby interpreter would pipe this to STDERR and exit 1 in the case of an unhandled exception b = e.backtrace @stderr.puts(\u0026#34;#{b.shift}: #{e.message} (#{e.class})\u0026#34;) @stderr.puts(b.map{|s| \u0026#34;\\tfrom #{s}\u0026#34;}.join(\u0026#34;\\n\u0026#34;)) 1 rescue SystemExit =\u0026gt; e e.status ensure # TODO: reset your app here, free up resources, etc. # Examples: # MyApp.logger.flush # MyApp.logger.close # MyApp.logger = nil # # MyApp.reset_singleton_instance_variables # ...then we put the streams back. $stderr = STDERR $stdin = STDIN $stdout = STDOUT end # Proxy our exit code back to the injected kernel. @kernel.exit(exit_code) end end end Now we can use VCR to mock our external services.\nWe can do that with hooks example.\nI have created features/support/webmock.rb file where I will store all my hooks.\nrequire \u0026#39;webmock/cucumber\u0026#39; CODEWARS_BASE = \u0026#39;https://www.codewars.com\u0026#39; CODEWARS_API = \u0026#39;/api/v1\u0026#39; Before(\u0026#39;@stub_user_response\u0026#39;) do api_key = \u0026#39;fake_api\u0026#39; stub_get(\u0026#34;/users/GustavoCaso\u0026#34;) .with( headers: { Authorization: api_key } ).to_return(json_response \u0026#39;user.json\u0026#39;) end def stub_get(url) stub_request(:get, \u0026#34;#{CODEWARS_BASE}#{CODEWARS_API}#{url}\u0026#34;) end def json_response(file, status=200) { body: fixture(file), status: status, headers: { content_type: \u0026#39;application/json; charset=utf-8\u0026#39; } } end def fixture(file) File.new(File.join(fixture_path,file)) end def fixture_path File.expand_path(\u0026#39;../../fixtures\u0026#39;, __FILE__) end And inside the features test we can use this hook.\nFeature: Display the user information in the terminal Background: Given a mocked home directory Given the config file with: \u0026#34;\u0026#34;\u0026#34; :api_key: \u0026#39;fake_api\u0026#39; :language: \u0026#39;\u0026#39; :folder: \u0026#39;\u0026#39; \u0026#34;\u0026#34;\u0026#34; @stub_user_response Scenario: Passing a valid username prints a correct message When I run `codewars user GustavoCaso` Then the output should contain \u0026#34;Displaying information about GustavoCaso\u0026#34; This is all I have learn about Aruba for testing your applications, I think is a great tool, that remove us from the pain of having to create to many step_definitions and let us focus on testing our application. I know there is to much to learn about Aruba and testing in general and if you have any questions or comments about the subject please do not hesitate.\n","date":"17 January 2016","permalink":"/posts/testing-command-line-applications-with-aruba/","section":"Posts","summary":"In the last couple of weeks I have been working, with a little project of my own. I always love Command Line Tools, I don\u0026rsquo;t know what they have but using them make feel more like a Hackers or someone that actually know what he is doing.","title":"Testing Comamnd-Line Applications with Aruba"},{"content":"","date":"11 November 2015","permalink":"/tags/rake/","section":"Tags","summary":"","title":" rake"},{"content":"","date":"11 November 2015","permalink":"/tags/rspec/","section":"Tags","summary":"","title":" rspec"},{"content":"This is the second part of my previous post Improving our rake tasks.\nIn this one we will discuss a way for testing our rake task, the example will be very straight forward. We will invoke the rake task and expect that some class receive the correct arguments.\nI will use Rspec as my test framework.\nAnd I will continue with the same example from last post.\nrequire \u0026#39;rake\u0026#39; describe \u0026#39;wunderground_daily rake task\u0026#39; do before(:each) do load File.expand_path(\u0026#39;tasks/wunderground_daily.rake\u0026#39;, __FILE__) Rake::Task.define_task(:environment) end after(:each) do Rake::Task.clear end context \u0026#39;wunderground_daily:check_flights\u0026#39; do it \u0026#39;call WeatherInformation with correct class and method\u0026#39; do expect(WeatherInformation).to receive(:get_weather_information).with(Pathify::Flight, :airport_destination) Rake::Task[\u0026#39;wunderground_daily:check_flights\u0026#39;].invoke end end context \u0026#39;wunderground_daily:check_trains\u0026#39; do it \u0026#39;call WeatherInformation with correct class and method\u0026#39; do expect(WeatherInformation).to receive(:get_weather_information).with(Pathify::TrainReservation, :station_destination) Rake::Task[\u0026#39;wunderground_daily:check_trains\u0026#39;].invoke end end end So the first we do is load rake and we create a before block which will be executed before every test. We load in memory the file where our tasks life, so rake will know what task to execute. And we seat up the environment\nThe after block took some time to figured out why, but I was geeting failing test because I was missing this one. Rake will store all the task that has been assigned, so the test where sharing the result, or so the expectation wasn\u0026rsquo;t met.\nThere is this great documentation for Rake, I really encourage to look it Rake\nFinally in our test we have to invoke our task, to execute it and see what results are we getting.\nAlso point out because we previously refactor our rake this test is really easy to implement. I will continue this series of post with a more complete one, focus on testing.\nThanks for reading, any comments please don\u0026rsquo;t hesitate.\n","date":"11 November 2015","permalink":"/posts/testing-your-rake-tasks/","section":"Posts","summary":"This is the second part of my previous post Improving our rake tasks.\nIn this one we will discuss a way for testing our rake task, the example will be very straight forward.","title":"Testing your rake tasks"},{"content":"Lately I have been writting some rake tasks, for downloading backups, for accesing API\u0026rsquo;s, or for automating teadious and repetitive work. Rake task are great, but dangerous at the same time.\nWe tend to add so much code to our rake task, that they become a source of errors. Following the principles of OOP we can clean our rake tasks, improving our code and making them much easier to test.\nLet\u0026rsquo;s look up an example from work:\nnamespace :wunderground_daily do desc \u0026#39;Get all flights on 10 days before depart and get weather for airports\u0026#39; task check_flights: :environment do w_api = Wunderground.new(secret) #o_O flights = Flight.future.lt(utc_arrival_date: (Time.now.utc + 10.days)) flights.each do |fl| if airport_code = fl.airport_destination # If there are any flight without weather or has flight in 2 days, update info wo = airport_code.weather_observations.where(date: fl.utc_arrival_date.beginning_of_day) if wo.empty? || fl.utc_arrival_date.beginning_of_day == (Date.today + 2.days) \u0026amp;\u0026amp; !wo.last.updated_at.today? puts fl.id response = w_api.forecast10day_for(\u0026#34;#{airport_code.latitude},#{airport_code.longitude}\u0026#34;) calls_count += 1 puts \u0026#34;#{airport_code.latitude},#{airport_code.longitude}\u0026#34; if response[\u0026#34;forecast\u0026#34;] response[\u0026#34;forecast\u0026#34;][\u0026#34;simpleforecast\u0026#34;][\u0026#34;forecastday\u0026#34;].each do |forecastday| airport_code.create_weather_observation(forecastday, fl) end end end end end end end As you can see the rake task is pretty big and involve multiple things.\nConnecting to an external Service Wunderground Fetching valid records Updating record with the data from the response This type of code is difficult to read and difficult to test, so extracting behaviour to different classes could improve the readability and scalability for the future.\nUsually in my process of refactoring code involve multiple steps, extracting logic to method, moving that method to a class and test. In a perfect world the test are written first but the world is not as perfect as wanted.\nSo following the steps I extract the logic into a method.\nnamespace :wunderground_daily do desc \u0026#39;Get all flights on 10 days before depart and get weather for airports\u0026#39; task check_flights: :environment do get_weather_information(Flight, :airport_destination) end def get_weather_information(model, target) w_api = Wunderground.new(secret) #o_O segments = model.future.lt(utc_arrival_date: (Time.now.utc + 10.days)) segments.each_with_index do |sg, i| if destination = sg.send(target) # If there are any train without weather or has train in 2 days, update info wo = destination.weather_observations.where(date: sg.utc_arrival_date.beginning_of_day) if wo.empty? || sg.utc_arrival_date.beginning_of_day == (Date.today + 3.days) \u0026amp;\u0026amp; !wo.last.updated_at.today? response = w_api.forecast10day_for(\u0026#34;#{airport_code.latitude},#{airport_code.longitude}\u0026#34;) if response[\u0026#34;forecast\u0026#34;] response[\u0026#34;forecast\u0026#34;][\u0026#34;simpleforecast\u0026#34;][\u0026#34;forecastday\u0026#34;].each do |forecastday| airport_code.create_weather_observation(forecastday, fl) end end end end end end So far so good, the rake task has reduce the size to just one line and all the logic is inside the new created method get_weather_information. But this is difficult to test and still this new method is doing to many things.\nSo we continue our path, and create a new class that will help with our rake task.\nclass WeatherInformation attr_reader :model, :target def initialize(model, target) @model = model @target = target end def get_segments model.future.lt(utc_arrival_date: (Time.now.utc + 10.days)) end def get_weather_observations(destination) destination.weather_observations.where(date: sg.utc_arrival_date.beginning_of_day) end def get_information(model, target) segments = get_segments segments.each_with_index do |sg, i| if destination = sg.send(target) # If there are any train without weather or has train in 2 days, update info wo = get_weather_observations(destination) if wo.empty? || sg.utc_arrival_date.beginning_of_day == (Date.today + 3.days) \u0026amp;\u0026amp; !wo.last.updated_at.today? update_weather_destination(destination) end end end end def update_weather_destination(destination) w_api = Wunderground.new(secret) #o_O response = w_api.forecast10day_for(\u0026#34;#{destination.latitude},#{destination.longitude}\u0026#34;) if response[\u0026#34;forecast\u0026#34;] response[\u0026#34;forecast\u0026#34;][\u0026#34;simpleforecast\u0026#34;][\u0026#34;forecastday\u0026#34;].each do |forecastday| destination.create_weather_observation(forecastday, fl) end end end end This new class WeatherInformation will improve our work by allowing us to test the different methods and we are following the Single Responsability Principle.\nSo we are able to get the segments the current weather_information of our segments and update the information if needed.\nAs you can see each action has his own method, so is easier the change.\nRight now I\u0026rsquo;m pretty happy with the result, there is always room for improvment, we could move the call to the external api to a background job, but that is out of the scope of this read.\nExtracting this behaviour to a new class will help us in the future, if the Product Manager decided that we need weather information for our Train model.\nnamespace :wunderground_daily do desc \u0026#39;get weather information for our Models\u0026#39; task get_info: :environment do WeatherInformation.new(Flight, :airport_destination).get_weather_information WeatherInformation.new(Train, :airport_destination).get_weather_information end ends This post is getting a little long, I have the intention the talk about testing the rake task, but I will leave that one for the second part.\nThanks for the read. Please if you have any idea for improve just comment and I will answer as soon as possible.\n","date":"6 November 2015","permalink":"/posts/improving-our-rake-tasks/","section":"Posts","summary":"Lately I have been writting some rake tasks, for downloading backups, for accesing API\u0026rsquo;s, or for automating teadious and repetitive work. Rake task are great, but dangerous at the same time.","title":"Improving our rake tasks"},{"content":"#####Promises, what ??\nI consider myself a ruby developer, not one with long time professional experience, but one with a great attitude and eager to learn new technologies.\nLately I have been working more with JavaScript at the beginning I wasn\u0026rsquo;t really enthusiastic about the idea of working with JavaScript but the project itself really surprise me.\nFor starters it was built with React and Redux for managing the state of the application. It has been a big change to understand how they work and wrapping my head around the concept of Reducers, Store and Actions but I could say is awesome working with this new technologies.\nBut what really shine the most was the new API for the Promises, for me change the way for working with asynchronous actions.\nI promise is an operation that hasn\u0026rsquo;t complete yet, but is expected in the future. To work with a promise you will have to pass an executor or function and two callbacks as their arguments.\nvar promise = new Promise(function(callback1, callback2){ executor body }) For better understanding we will call the callbacks resolve and reject, those will be the actions that will take place after the body of the function or executor finish.\nPromises bring us a few methods than help us interact with them like then, catch, all and a few more, I\u0026rsquo;m not an expert, but I really recommend to have a look into the documentation. But for the sake of the post I will say is like an ajax call with all the callback.\nWith the previous example I will show a simple way of fetching a random joke from the Chuck Norris Database.\nvar promise = new Promise( function(resolve, reject) { var client = new XMLHttpRequest(); client.open(\u0026#39;GET\u0026#39;, \u0026#39;http://api.icndb.com/jokes/random\u0026#39;) client.onload = function(){ if (client.status == 200){ resolve(client.response); } else { reject(Error(client.statusText)); } }; client.send() }); promise.then(function(data){ console.log(data) }, function(statusText){ console.log(statusText) }) The example is pretty simple we make an asynchronous call to get a random joke and on the onload function if the response is correct we execute the resolve callback if not we execute the reject callback.\nThe then will wait for the get request to finish and then will execute the callback.\nThere is so much power with this new Promise API you can actually do really impressive things.\nOne of the things that request on my job was the possibility to fetch some data from the server, but the server was executing a background job, so there is no way of knowing when the job has finished. In this scenario we could use Promises to fetch data from the api doing some kind of polling until the server return an answer.\nThis is example is a little more tricky, but nothing you guys can understand. So the main idea is to halt the execution until we get an answer from the server, you could display a spinner a loading message whatever you want.\nOK down to business.\nfunction getData() { var intervalId; var promise = new Promise(function(resolve, reject){ function makeConnection(){ var client = new XMLHttpRequest() client.send(\u0026#39;Get\u0026#39;, \u0026#39;http://fake_endpont.com/pai/1/info.json\u0026#39;) client.onload = function() { if (client.status === 200 \u0026amp;\u0026amp; client.response.message === \u0026#39;complete\u0026#39;){ clearInterval(intervalId) resolve(client.response) } } } intervalId = setInterval(makeConnection, 1000) }); return promise; } function displayData(response) { console.log(response); } getData().then(displayData) Thanks to a colleague at work who help me out I was able to do it and understand it, basically we call a function that returns a promise, which executor will call a function that will fetch the data from the server, and will try to get the data every 10 seconds, when the data is what we want will call the resolve function finishing the promise and clear the interval.\nThis code getData().then(displayData) will be call, but the resolve function will be executed when the code fulfill the condition.\nIs has been a long post, I thanks for reading and any mistake please don\u0026rsquo;t hesitate and comment.\n","date":"8 October 2015","permalink":"/posts/working-your-way-up-with-promises/","section":"Posts","summary":"#####Promises, what ??\nI consider myself a ruby developer, not one with long time professional experience, but one with a great attitude and eager to learn new technologies.\nLately I have been working more with JavaScript at the beginning I wasn\u0026rsquo;t really enthusiastic about the idea of working with JavaScript but the project itself really surprise me.","title":"Working your way up with promises"},{"content":"","date":"4 May 2015","permalink":"/tags/rails/","section":"Tags","summary":"","title":" rails"},{"content":"#####Implement Rails Variants in Rails 3.1\nYesterday at work we decided that we need to improve our user experience in web mobile. So we decided that it was time to create a different view for each action. Lately in Rails 4 there is this really cool feature called Variants really neat one if you ask me.\nBasically depending on the variant you set phone || tablet usually from an before_action inside your ApplicationController, rails will be smart enough to render the right layout and the right view, only with te condition that you add the variants to the file name show.html+mobile.erb.\nOk so easy as pie. Our problem we have a complex rails 3.2 application with a lot of dependencies, that is quite difficult to upgrade to rails 4.1.\nSo I decided to implement a simple but effective variation of the variants #to manny variants around :)\nAt first I was quite lost how to implement this the best way possible, well my first approach was to create a simple method render_template that added to every controller action will decided with template to use base on the request.user_agent. Of course that wasn\u0026rsquo;t the best idea but I have to write a lot of respond_to blocks all over te application.\nOne friend of mine point to right direction Rails Resolvers, also to this great book Crafting Rails Appliactions.\nSo basically there some awesome tutorials for building this plugins to extend rails functionality, and a lot of information about the new Api they have.\nIt\u0026rsquo;s true that is not easy finding documentation for the internal classes around Rails like ActionView::Resolver.\nOk so armed with my book and my enthusiasm I decided to give it another try.\nBasically want I had to do was create a simple class called ¬¥MobileViewResolver¬¥ with just two methods.\nclass MobileViewresolver \u0026lt; ::ActionView::FileSystemResolver def initialize super(\u0026#39;app/views\u0026#39;, \u0026#34;:prefix/:action{.:locale,}{.:formats,}{+:variants,}{.:handlers,}\u0026#34;) end def find_templates(name, prefix, partial, details) details[\u0026#39;variants\u0026#39;] = [\u0026#39;mobile\u0026#39;] super(name, prefix, partial, details) end end The initialize method accept two parameters the path where to look for the templates and a pattern, in this case I use the one for rails 4.1 including the variants. The find_templates method receives the template name, a prefix (i.e. the controller path), a boolean marking if the template is a partial or not and a hash of details. We modify the details hash to include in our case our mobile variant and rails will look for that pattern inside the app/views folder. If no file is found it will fallback to the default ones. We only have to include in our controller this new resolver prepend_view_paths MobileViewResolver.new. And that is all.\nWe manage to add this new feature with just one simple class.\nRails has some awesome API waiting to be use.\n","date":"4 May 2015","permalink":"/posts/using-rails-resolver-api/","section":"Posts","summary":"#####Implement Rails Variants in Rails 3.1\nYesterday at work we decided that we need to improve our user experience in web mobile. So we decided that it was time to create a different view for each action.","title":"Using Rails Resolver Api"},{"content":"Last night I was reading some blogs about ruby patterns, for me is sometimes difficult to understand the use of this kind of patterns, mostly because in my work we just throw thousand of lines of code, and deal with a lot of legacy code from other person who contribute to our projects. I currently work for comparason website in Spain Kelisto Lately there is one projects that is architecture is strongly inheritance, so there are many classes that inherited from a parent class.\nThere are sometimes were there is no difference between then except for class name.\nReading about this Decorator where you are able to dynamically add more funcionality to your objects, keep me thinking is there any way I can create the same structure but instead with thousands of classes with Decorators.\nSo imagine a simple class Card with all it\u0026rsquo;s methods, validations etc\u0026hellip;\nclass Card def description \u0026#34;#{name}:#{self.class}\u0026#34; end def total_tax (year_fess + extra_charges / 5) *100 end end Imagine a bunch of methods more.\nOne day the stakeholder comes and says to you, we are going to have a new type of card. Quickly you think easy I just create a new type of card that inherited, and easy as pie we have our new card type. So basically have the same methods, or eventually we will add some methods that are the same for both, or just uniq depending of the specifications.\nSo I thought maybe I can use this pattern to create the same behavior, but without that many classes or models if you prefer. Using the Decorator pattern I can create some modules with custom behavior for my card class and then added to them. This way I dont create a new class just super charge my class with this methods.\nmodule CreditCardModule def total_tax super + credit_card_fees end def description \u0026#34;#{name}: CreditCard\u0026#34; end end This way I won\u0026rsquo;t have a lot of class/models but one card class that I will dynamically add more functionality\nclass Card include CreditCardModule . . . end ```ruby ##### Decorators not always the best solution This pattern is not always the best solution of course, what if the credit card have some fields that are only for this type of card, in that case inheritance is a good option to have in mind. With that in mind there are other solutions that could come more efficient. I will continue this line of thought in future publications. ","date":"28 February 2015","permalink":"/posts/decorator-pattern/","section":"Posts","summary":"Last night I was reading some blogs about ruby patterns, for me is sometimes difficult to understand the use of this kind of patterns, mostly because in my work we just throw thousand of lines of code, and deal with a lot of legacy code from other person who contribute to our projects.","title":"Decorator Pattern"},{"content":"","date":"30 July 2014","permalink":"/tags/heroku/","section":"Tags","summary":"","title":" heroku"},{"content":"Before deploy in production is always recommended to test everything first, probably you have a Test suit for test your application, but you never know want is going to happen when you deploy all changes to production. What people usually do is create a staging environment, that copies the production environment.\nBasically you deploy first to staging and then test evrything, so after checking everything you may deploy to production with the confidence that everything works perfectly. Heroku as I said before is amazing it allow\u0026rsquo;s us to create multiple environments, Heroku provides us with many documentation to create our environments. Managing Multiple Environments for an App This post show us how to create different environments. The problem is if you have an existing App is not very clear how to do it, but I shall help you do it.\nFrom our terminal, we must have Heroku Toolbelt installed, to allow us use the command line. Heroku has method call fork that will clone an existing app into another, you don\u0026rsquo;t need to create app the first, heroku will create the app and clone everything into this new app.\n$ heroku fork -a your-app-name your-app-name-staging $ heroku fork -a your-app-name your-app-name-staging --region eu # there the posibility to pass a region option Replace your-app-name with the actual name of your app and your-app-name-staging with the name for the staging environment you want. This process might take some time.\nAfter that we must add a new remote to git so we can push to it.\n$ git add remote staging git@heroku.com:your-app-name-staging.git Now we can push to staging git push staging master\nAfter that you may go a little further you can install a gem Paratrooper that help us with the deployment task.\nThe basic use of this gem is pretty simple we have to create a rake task inside our lib/task folder call it deploy.rake and place this code.\nrequire \u0026#39;paratrooper\u0026#39; namespace :deploy do desc \u0026#34;deploy to staging\u0026#34; task :staging do deployment = Paratropper::Deploy.new(\u0026#39;your-app-name-staging\u0026#39;, tag: \u0026#39;staging\u0026#39;) deployment.deploy end desc \u0026#34;deploy to production\u0026#34; task :production do deployment = Paratrooper::Deploy.new(\u0026#39;your-app-name\u0026#39;) do |deploy| deploy.tag = \u0026#39;production\u0026#39; deploy.match_tag = \u0026#39;staging\u0026#39; end deployment.deploy end end With this file in our app we can call the different rake tasks rake deploy:staging or rake deploy:production.\nInside the production task is deploy.match_tag = 'staging'. This signifies that we only will push to production, what has been push to staging, this way we can not skip the staging part.\n","date":"30 July 2014","permalink":"/posts/set-up-a-simple-deployment-system/","section":"Posts","summary":"Before deploy in production is always recommended to test everything first, probably you have a Test suit for test your application, but you never know want is going to happen when you deploy all changes to production.","title":"Set up a simple deployment system"},{"content":"","date":"8 July 2014","permalink":"/tags/associations/","section":"Tags","summary":"","title":" associations"},{"content":"When I first heard about this concept I was a little bit confuse. I was reading Learn rails by Example by Michael Hart\nBy that time the concept was to much for me, so I did some research. I found Railscast episode Self-referential Associations, it threw some light in the concept, but I still confuse.\nRight now I think I understand the concept a little bit better but there always room for improvement. I\u0026rsquo;m going to show you the code for a simple self-referential association for friends and followers.\nclass User \u0026lt; ActiveRecord::Base has_many :reviews has_many :queue_items, -\u0026gt; {order(:position)} has_many :friendships, foreign_key: :user_id has_many :followers, class_name: \u0026#34;Friendship\u0026#34;, foreign_key: :friend_id has_secure_password validations: false validates_presence_of :full_name, :email def included_in_queue?(video) queue_items.include?(video) end end I have to say that Ryan Bates solution probably is more efficient than this one but for me this one looks more clear.\nOk, so we have a User model and a Friendship model that has user_id and friend_id. Now is time to link this two models. The line has_many :friendships, foreign_key: :user_id is telling ActiveRecord::Base to get all row from the friendships table where user_id and the current_user.id match.\nThis is the query:\nSELECT \u0026#34;friendships\u0026#34;.* FROM \u0026#34;friendships\u0026#34; WHERE \u0026#34;friendships\u0026#34;.\u0026#34;user_id\u0026#34; = ? [[\u0026#34;user_id\u0026#34;, 1]] Thanks to the method has_many and some of the options we are able to get what we want, the option foreign_key let us specify the foreign key used for the association.\nThe last line has_many :followers, class_name: \u0026quot;Friendship\u0026quot;, foreign_key: :friend_id let us get the people that are following us.\nBecause there is no followers table we have to specify the class_name in this case Friendships and the foreign_key option will help us specify the association.\nThis is the query:\nSELECT \u0026#34;friendships\u0026#34;.* FROM \u0026#34;friendships\u0026#34; WHERE \u0026#34;friendships\u0026#34;.\u0026#34;friend_id\u0026#34; = ? [[\u0026#34;friend_id\u0026#34;, 1]] I\u0026rsquo;m sure there are probably more better ways to do it but this one help me understand it better.\n","date":"8 July 2014","permalink":"/posts/self-referential-associations/","section":"Posts","summary":"When I first heard about this concept I was a little bit confuse. I was reading Learn rails by Example by Michael Hart\nBy that time the concept was to much for me, so I did some research.","title":"Self-referential Associations"},{"content":"Recently reading the some posts about ruby I found myself with this interesting method call lazy. This method will help us when looping over some objects: Array, Hashes, Files \u0026hellip;\u0026hellip;. If you want to loop though an array that is huge, an we only want to select the first 20 element that evaluate our criteria, this is the kind of job for our lazy method.\nWithout Lazy # arr = (1..1000).to_a selected = [] arr.select do |x| selected \u0026lt;\u0026lt; x if x.odd? break if selected.size \u0026gt; 20 end p selected This looks familiar but we may use the lazy method.\nWith Lazy method # arr = (1..1000).to_a selected = arr.lazy.select do |x| x if x.odd? end.take(20).force p selected This way the syntax is more clear and is better in performance.\n","date":"3 July 2014","permalink":"/posts/enumerator-lazy/","section":"Posts","summary":"Recently reading the some posts about ruby I found myself with this interesting method call lazy. This method will help us when looping over some objects: Array, Hashes, Files \u0026hellip;\u0026hellip;. If you want to loop though an array that is huge, an we only want to select the first 20 element that evaluate our criteria, this is the kind of job for our lazy method.","title":"Enumerator"},{"content":"","date":"9 May 2014","permalink":"/tags/active-record/","section":"Tags","summary":"","title":"Active Record"},{"content":"While reading the documentation of ActiveRecord::Associations, there are many useful methods, that I didn¬¥t know about it. But one came to me as quite useful, inverse_of. This method allow us to work with associations that haven`t been save yet, so it will work with the memory. This will optimise our object loading.\nI will so you with some example.\nClass Post \u0026lt; ActiveRecord::Base has_many :comments, inverse_of :post end Class Comment \u0026lt; ActiveRecord::Base belongs_to :post, inverse_of :comments end Setting like this our models will allow to do some nice thing in our console.\np = Post.create =\u0026gt; #\u0026lt;Post id: nil, name: nil \u0026gt; c = p.comments.create =\u0026gt; #\u0026lt;Comment id: nil, body: nil \u0026gt; c.post =\u0026gt; #\u0026lt;Post id: nil, name: nil \u0026gt; Without the inverse the last line will return nil because is trying to hit the database but there isn\u0026rsquo;t any record save in it\n","date":"9 May 2014","permalink":"/posts/inverse-of/","section":"Posts","summary":"While reading the documentation of ActiveRecord::Associations, there are many useful methods, that I didn¬¥t know about it. But one came to me as quite useful, inverse_of. This method allow us to work with associations that haven`t been save yet, so it will work with the memory.","title":"Inverse_of ActiveRecord"},{"content":"","date":"23 April 2014","permalink":"/tags/postgresql/","section":"Tags","summary":"","title":" postgresql"},{"content":"Recently I was playing around with my local database in my rails project, eventually I screw up, I had to delete all the data. I use rake db:resetand rake db:create but how I was going to get all the data again, manually ? No way.\nHeroku is a great tool for deploying.\nWith three simple lines of code in your terminal you are able to download your production database and load it in your local envairoement.\nIn your terminal and in your project folder type:\n$ heroku pgbackups:capture $ curl -o latest.dump `heroku pgbackups:url` This two line create a backup and read it to file call latest.dump.\n$ pg_restore --verbose --clean --no-acl --no-owner -h localhost -U myuser -d mydb latest.dump With this last line we are restoring the database from the backup file, remember change myuser for your actual user and mydb for your database name.\nHope this helps.\n","date":"23 April 2014","permalink":"/posts/exporting-and-import-heroku-db/","section":"Posts","summary":"Recently I was playing around with my local database in my rails project, eventually I screw up, I had to delete all the data. I use rake db:resetand rake db:create but how I was going to get all the data again, manually ?","title":"Exporting and Import Heroku DB"},{"content":"","date":"21 April 2014","permalink":"/tags/delayed_job/","section":"Tags","summary":"","title":" delayed_job"},{"content":"Sending emails with rails and Heroku (Updated 2014-04-24)\nRails makes extremly easy to send emails, I\u0026rsquo;m not going to explain how to do it, there are pretty good tutorials around the internet, this one is really well explain: Action Mailer Basics.\nIt is common to delay the task in our rails applications, that way the app doesn\u0026rsquo;t stop. There are many good gems that help us, I usually use is delayed_job. This gems makes it really easy, we just have to prepend delay in our process Mailer.delay.sendMail(args).\nIn my actual project some of the mails we send, has attachments files, usually for that type of task it is common to create a temp file that store the information, and send it as arguments to mailer action.\nInside our controller.\ntemp_file = Tempfile.new(\u0026#34;new_file.csv\u0026#34;) temp_file.write (\u0026#34;Hello\u0026#34;) temp_file.write (\u0026#34;\\n\u0026#34;) temp_file.write (\u0026#34;World\u0026#34;) temp_file.rewind temp_file.close Mailer.sendMail(temp_file).deliver temp_file.unlink Inside our Mailer class code could be like this:\nclass Mailer \u0026lt; ActionMailer::Base def send_mail(file) attachments[\u0026#39;filename.csv\u0026#39;] = File.read(file.path) mail(to: foo@bar.com, subject: \u0026#39;Welcome to My Awesome Site\u0026#39;) end end Thats one way of doing it, but Heroku do not allow us to write file in the system, do to the file system they have. There multiple solutions to this problem, basically we can store the file in one of the store service like S3. To use the S3 service we must add a gem to our Gemfile gem 'aws-sdk'\nOnce the file is uploaded to the S3 it will be posible to download it and attach it to the email.\nSo how we could do this:\nLets create the file and write what ever we want, in my case I created some helper method to create the file and store it in S3. Inside app/controller/helpers.\n# We must write this to use the S3 store file require \u0026#39;aws-sdk\u0026#39; class create_file # This way the file will be created and close when the block is finish file = File.open(\u0026#34;#{Rails.root}/tmp/filename.txt\u0026#34;, \u0026#34;w+\u0026#34;) do |f| f.write (\u0026#34;Hello\u0026#34;) f.write (\u0026#34;\\n\u0026#34;) f.write (\u0026#34;World\u0026#34;) end file end class store_S3(file) # We create a connection with amazon S3 AWS.config( :access_key_id =\u0026gt; ENV[\u0026#39;AWS_ACCESS_KEY_ID\u0026#39;], :secret_access_key =\u0026gt; ENV[\u0026#39;AWS_SECRET_ACCESS_KEY\u0026#39;] ) s3 = AWS::S3.new bucket = s3.buckets[ENV[\u0026#39;S3_BUCKET_NAME\u0026#39;]] object = bucket.objects[File.basename(file)] # the file is not the content of the file is the route object.write(:file =\u0026gt; file) # save the file and return an url to download it object.url_for(:read) end With this two method we are able to create and store the file in AWS, no is the easy part send the email.\nInside our controller we could call our mailer with our file url, to read from and send the email.\nclass SaleController \u0026lt; ApplicationController::Base def send_email file = create_file url = store_S3(file) Mailer.delay.send_mail(url) end end And for the last touch, inside our Mailer\nclass Mailer \u0026lt; ActionMailer::Base def send_mail(url) attachments[\u0026#39;filename.csv\u0026#39;] = open(url).read mail(to: foo@bar.com, subject: \u0026#39;Welcome to My Awesome Site\u0026#39;) end end I hope this could help anyone, there are some problems with heroku if the file is to big there might be some problems, I\u0026rsquo;m working to solve it, hopefuly I could get and answer and share with all of you.\nHappy coding.\n","date":"21 April 2014","permalink":"/posts/delayed-job-and-send-email/","section":"Posts","summary":"Sending emails with rails and Heroku (Updated 2014-04-24)\nRails makes extremly easy to send emails, I\u0026rsquo;m not going to explain how to do it, there are pretty good tutorials around the internet, this one is really well explain: Action Mailer Basics.","title":"Delayed job and Send email with Attachements"},{"content":"I\u0026rsquo;m new to Octopress platform for Blogging, but so far I think is great and simple.\nCreating my first post I felt so excited, as when you discover a new treasure or a secret path in your favorite game. But everything at the beginning is not going to be smooth. My first problem was that my post weren\u0026rsquo;t displaying the Disqus comments, that are a very common system for comments in the blog community.\nAfter hours of searching the web and reading lot of post about the topic I had a goodunderstand of how to integrated them.\nSo I thought of sharing my experience:\nFisrt you have to register you site in Disqus, you will receive a short code. After that go to your _config.yml file inside your project and add it.\ndisqus_short_name: ***************** disqus_show_comment_count: false After that make sure that you allow comments in your post. Inside source/_posts/ there will be all your post, and on the top are some configuration :\n--- layout: post title: \u0026#34;File rename\u0026#34; date: 2014-04-13 18:48:47 +0200 tags: ruby --- And that\u0026rsquo;s it, or wasn\u0026rsquo;t ?\nBut it didn\u0026rsquo;t work, I went on a quest for solving this. Octopress uses the liquid syntax for loading the different layouts, reading the post layout inside source/_layouts/_posts you will see that load a file call disqus_thread.html, I looked for it and found it, and saw this:\n\u0026lt;noscript\u0026gt;Please enable JavaScript to view the \u0026lt;a href=\u0026#34;http://disqus.com/?ref_noscript\u0026#34;\u0026gt;comments powered by Disqus.\u0026lt;/a\u0026gt;\u0026lt;/noscript\u0026gt; Felt a little weird, that\u0026rsquo;s not what you expect, searching in the wide Internet some people talked about another file disqus.html inside the _include folder, once there the code felt more appropiated. Copying that inside disqus_thread.html the problem solve.\n\u0026lt;script type=\u0026#34;text/javascript\u0026#34;\u0026gt; var disqus_shortname = \u0026#39;{{ site.disqus_short_name }}\u0026#39;; {% if page.comments == true %} {% comment %} `page.comments` can be only be set to true on pages/posts, so we embed the comments here. {% endcomment %} // var disqus_developer = 1; var disqus_identifier = \u0026#39;{{ site.url }}{{ page.url }}\u0026#39;; var disqus_url = \u0026#39;{{ site.url }}{{ page.url }}\u0026#39;; var disqus_script = \u0026#39;embed.js\u0026#39;; {% else %} {% comment %} As `page.comments` is empty, we must be on the index page. {% endcomment %} var disqus_script = \u0026#39;count.js\u0026#39;; {% endif %} (function () { var dsq = document.createElement(\u0026#39;script\u0026#39;); dsq.type = \u0026#39;text/javascript\u0026#39;; dsq.async = true; dsq.src = \u0026#39;http://\u0026#39; + disqus_shortname + \u0026#39;.disqus.com/\u0026#39; + disqus_script; (document.getElementsByTagName(\u0026#39;head\u0026#39;)[0] || document.getElementsByTagName(\u0026#39;body\u0026#39;)[0]).appendChild(dsq); }()); \u0026lt;/script\u0026gt; \u0026lt;noscript\u0026gt;Please enable JavaScript to view the \u0026lt;a href=\u0026#34;http://disqus.com/?ref_noscript\u0026#34;\u0026gt;comments powered by Disqus.\u0026lt;/a\u0026gt;\u0026lt;/noscript\u0026gt; Hope I could help.\n","date":"14 April 2014","permalink":"/posts/integrate-disqus-with-octopress/","section":"Posts","summary":"I\u0026rsquo;m new to Octopress platform for Blogging, but so far I think is great and simple.\nCreating my first post I felt so excited, as when you discover a new treasure or a secret path in your favorite game.","title":"Integrate Disqus with Octopress"},{"content":"","date":"14 April 2014","permalink":"/tags/octopress/","section":"Tags","summary":"","title":"octopress"},{"content":"In a rails project I\u0026rsquo;m working on I was trying to select from the database some sales with some conditions.\nTo start the Sale model has multiples associations .\nclass Sale \u0026lt; ActiveRecord::Base belongs_to :voucher belongs_to :client has_many :line_items, dependent: :destroy has_many :bills end So the goal of this select was to obtain all the Sales where the LineItems has express_checkout set it to true.\nI thought it was easy, in the Sales controller I will get all the sales Sales.all do a select Sales.all.select that\u0026rsquo;s the easy part, inside the block is were I got lost, because I have access to sale not the line_items associated to it, I started trying to fetch the line_items and perform another select inside.\nSales.all.select do |sale| sale.line_items.select do |line_item| line_item.express_checkout == true end end So I see this code and thought that must be right, but I keep getting all the Sales.\nA friend of mine told to extract a method for this kinf of task in the Salesmodel, so I gave it a try, and created a new method call express_checkout?. This method did basically the same but instead I store the result of the select in a variable and then check if there where any object inside that variable. That approach worked.\nSo my thoughts were inside the select always will return an array with the elemnts that passed from the condition, but I didn\u0026rsquo;t know we have to store them in a variable and then check it.\nThe final code:\ndef express_production? l = line_items.select{|line_item| line_item.express_checkout == true} l.any? end ","date":"14 April 2014","permalink":"/posts/rails-and-select/","section":"Posts","summary":"In a rails project I\u0026rsquo;m working on I was trying to select from the database some sales with some conditions.\nTo start the Sale model has multiples associations .\nclass Sale \u0026lt; ActiveRecord::Base belongs_to :voucher belongs_to :client has_many :line_items, dependent: :destroy has_many :bills end So the goal of this select was to obtain all the Sales where the LineItems has express_checkout set it to true.","title":"Rails and select"},{"content":"Postgresql ORDER clause or be used in a aggregate function\nWhile working in a rails project recently, I step on an error that say: PG::Error: ERROR: column \u0026quot;number\u0026quot; must appear in the GROUP BY clause or be used in an aggregate function, I didn\u0026rsquo;t have any idea how to solve it.\nReading for a while I think I have a small understand, why this error appear.\nWe have to specify which column should be use for the GROUP BY or for the ORDER inside our SELECT for example Sale.all.select(:ordered_on, :number).group(:ordered_on, :number).order(:number).\nWith this query , we are able to retrieve all sales group by ordered_on and number and order by it as well.\nThis error jump while using Postgresql because it is more restrictive than MySQL. So remember be careful if you are deploying to Heroku because it\u0026rsquo;s default database.\nHope this help you.\nHere are some good references for the future. Postgresql Tutorial\n","date":"14 April 2014","permalink":"/posts/rails-postgresql-error-order/","section":"Posts","summary":"Postgresql ORDER clause or be used in a aggregate function\nWhile working in a rails project recently, I step on an error that say: PG::Error: ERROR: column \u0026quot;number\u0026quot; must appear in the GROUP BY clause or be used in an aggregate function, I didn\u0026rsquo;t have any idea how to solve it.","title":"Rails Postgresql Error ORDER clause"},{"content":"While doing some exercise of the book Learn to Program of Chris Pine, trying to rename some files as part of some exercise, that was renaming a bunch of picture from a folder, I noticed a strange functionality.\nUsing the method File.rename(old_name, new_name) and after running my program it seems that the file haven\u0026rsquo;t been rename instead it has been deleted, but that\u0026rsquo;s not what happen. What ruby was doing is renaming and moving the file to my printing working directory. What really solve it was giving an absolute path to the method.\nFile.rename(old_name, \u0026quot;/Users/gus/Desktop/myImages/new_name\u0026quot;)\nAnd I thought that was some tedious work, I look up in Ruby doc and found that ruby is smart enough to provide with a method. File.join(Dir.pwd, \u0026quot;new_name\u0026quot;) this method will concatenate every string we pass it, providing the path to our file.\nThis is my final code for the exercise.\nDir.chdir \u0026#34;../../Desktop/Images\u0026#34; pictures = Dir[\u0026#39;*.{jpg,jpeg}\u0026#39;] pictures.each do |picture| puts \u0026#34;The #{picture} is inside the folder what do you want to do: 1) rename, 2) delete, 3) nothing\u0026#34; answer = gets.chomp.to_i if answer == 1 puts \u0026#34;So you want to rename it. Good what you want to rename it\u0026#34; answer = gets.chomp File.rename(picture, File.join(Dir.pwd, answer)) puts \u0026#34;The picture now it is #{answer}\u0026#34; elsif answer == 2 puts \u0026#34;You want to delete it\u0026#34; File.delete(picture) unless File.exists?(picture) puts \u0026#34;The file has been delete it\u0026#34; end else puts \u0026#34;so you want to do nothing to the file\u0026#34; puts \u0026#34;Done !!!!\u0026#34; end end puts \u0026#34;Thanks for handeling our images\u0026#34; ","date":"13 April 2014","permalink":"/posts/file-rename-in-ruby/","section":"Posts","summary":"While doing some exercise of the book Learn to Program of Chris Pine, trying to rename some files as part of some exercise, that was renaming a bunch of picture from a folder, I noticed a strange functionality.","title":"File rename in ruby"}]